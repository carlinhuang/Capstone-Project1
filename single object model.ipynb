{"cells":[{"cell_type":"markdown","metadata":{"id":"Ta7MDGgbZLsV"},"source":["# Setup\n","\n","Pip install `ultralytics` and [dependencies](https://github.com/ultralytics/ultralytics/blob/main/requirements.txt) and check software and hardware."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11411,"status":"ok","timestamp":1698025575595,"user":{"displayName":"Cynthia Cheng","userId":"11720369831058397288"},"user_tz":420},"id":"3r6ITRXIZNlK","outputId":"82d9c6f2-b48e-4944-ec70-6cf97728658f"},"outputs":[{"name":"stderr","output_type":"stream","text":["Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.1.0+cu118 CUDA:0 (Tesla V100-SXM2-16GB, 16151MiB)\n","Setup complete âœ… (8 CPUs, 51.0 GB RAM, 27.1/166.8 GB disk)\n"]}],"source":["%pip install ultralytics\n","import ultralytics\n","ultralytics.checks()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2398,"status":"ok","timestamp":1698028061074,"user":{"displayName":"Cynthia Cheng","userId":"11720369831058397288"},"user_tz":420},"id":"honLeLxoZUhT","outputId":"335ef413-e193-43ac-b9e1-e1ed9b1e1046"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"rnrzkITGZlKC"},"source":["## train model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":828,"status":"ok","timestamp":1698028071719,"user":{"displayName":"Cynthia Cheng","userId":"11720369831058397288"},"user_tz":420},"id":"g145mlziZnMD","outputId":"75f99575-e83b-49ba-e031-ff3c54c81f99"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/.shortcut-targets-by-id/1xXZ2ldeRl7gFnlMnyoptyZpnfIdhf68X/capstone/colab\n"," \u001b[0m\u001b[01;34mdata\u001b[0m/                 \u001b[01;34m'quickdraw data'\u001b[0m/  'single object model.ipynb'   \u001b[01;34mYOLOv8\u001b[0m/\n","'download file.ipynb'   \u001b[01;34mruns\u001b[0m/              \u001b[01;34myolov8\u001b[0m/                      yolov8n.pt\n"]}],"source":["%cd /content/drive/MyDrive/capstone/colab\n","%pwd\n","%ls"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":893244,"status":"ok","timestamp":1698021452321,"user":{"displayName":"Cynthia Cheng","userId":"11720369831058397288"},"user_tz":420},"id":"MGIwmPMbZykO","outputId":"3ee165bc-e930-4272-8d2c-19f3b726cee8"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/.shortcut-targets-by-id/1xXZ2ldeRl7gFnlMnyoptyZpnfIdhf68X/capstone/colab\n","Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.1.0+cu118 CUDA:0 (Tesla V100-SXM2-16GB, 16151MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=YOLOv8/yolov8n/yolov8n.pt, data=data/data.yml, epochs=3, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=single_model2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/single_model2\n","Overriding model.yaml nc=80 with nc=43\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n","  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n","  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n","  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n"," 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n"," 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 22        [15, 18, 21]  1    759697  ultralytics.nn.modules.head.Detect           [43, [64, 128, 256]]          \n","Model summary: 225 layers, 3019233 parameters, 3019217 gradients, 8.2 GFLOPs\n","\n","Transferred 319/355 items from pretrained weights\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/single_model2', view at http://localhost:6006/\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/.shortcut-targets-by-id/1xXZ2ldeRl7gFnlMnyoptyZpnfIdhf68X/capstone/colab/data/train/labels/apple.cache... 30100 images, 0 backgrounds, 0 corrupt: 100% 30100/30100 [00:00<?, ?it/s]\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/.shortcut-targets-by-id/1xXZ2ldeRl7gFnlMnyoptyZpnfIdhf68X/capstone/colab/data/valid/labels/apple.cache... 8600 images, 0 backgrounds, 0 corrupt: 100% 8600/8600 [00:00<?, ?it/s]\n","Plotting labels to runs/detect/single_model2/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000213, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1mruns/detect/single_model2\u001b[0m\n","Starting training for 3 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","        1/3      2.42G     0.9197      3.686      1.569         11        640: 100% 1882/1882 [03:39<00:00,  8.59it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 269/269 [00:47<00:00,  5.72it/s]\n","                   all       8600       8600      0.362      0.426      0.369      0.352\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","        2/3      2.46G     0.5762      2.437      1.269          8        640: 100% 1882/1882 [03:29<00:00,  8.99it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 269/269 [00:44<00:00,  6.01it/s]\n","                   all       8600       8600      0.585      0.603      0.624      0.611\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","        3/3      2.45G      0.469      2.069      1.186         11        640: 100% 1882/1882 [03:23<00:00,  9.23it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 269/269 [00:44<00:00,  5.98it/s]\n","                   all       8600       8600      0.652      0.679      0.726      0.698\n","\n","3 epochs completed in 0.215 hours.\n","Optimizer stripped from runs/detect/single_model2/weights/last.pt, 6.3MB\n","Optimizer stripped from runs/detect/single_model2/weights/best.pt, 6.3MB\n","\n","Validating runs/detect/single_model2/weights/best.pt...\n","Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.1.0+cu118 CUDA:0 (Tesla V100-SXM2-16GB, 16151MiB)\n","Model summary (fused): 168 layers, 3014033 parameters, 0 gradients, 8.1 GFLOPs\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 269/269 [00:49<00:00,  5.48it/s]\n","                   all       8600       8600      0.651      0.678      0.726      0.699\n","                 apple       8600        200      0.722       0.91      0.936      0.901\n","              backpack       8600        200      0.606      0.535      0.582      0.551\n","                banana       8600        200      0.678       0.73      0.741      0.712\n","            basketball       8600        200      0.739      0.645      0.754      0.721\n","                   bed       8600        200      0.542      0.592      0.561      0.553\n","               bicycle       8600        200      0.669      0.809      0.843      0.804\n","                  book       8600        200      0.754      0.629      0.714      0.679\n","                bucket       8600        200      0.825       0.82      0.889      0.869\n","                  cake       8600        200      0.639       0.78      0.797      0.768\n","              calendar       8600        200      0.614      0.564       0.64      0.606\n","                 chair       8600        200      0.866      0.843      0.919      0.895\n","                 clock       8600        200      0.821      0.871      0.906      0.838\n","                 couch       8600        200      0.508       0.82      0.747      0.711\n","                   dog       8600        200       0.66      0.368       0.53      0.508\n","              dumbbell       8600        200      0.552      0.715      0.684      0.636\n","            eyeglasses       8600        200      0.508      0.845       0.83      0.802\n","                   fan       8600        200      0.715      0.726      0.781      0.762\n","                guitar       8600        200      0.545      0.405      0.485      0.479\n","                   hat       8600        200      0.498       0.77      0.742       0.73\n","                jacket       8600        200       0.49      0.925      0.895      0.862\n","                   key       8600        200      0.299       0.28      0.304      0.292\n","                laptop       8600        200      0.582      0.575      0.599      0.591\n","                 pants       8600        200       0.85       0.86      0.903      0.872\n","                pencil       8600        200      0.595      0.775      0.782      0.765\n","                 piano       8600        200      0.475       0.65       0.64      0.595\n","                pillow       8600        200      0.826      0.737      0.791      0.757\n","                rabbit       8600        200      0.701       0.31      0.561      0.543\n","                 radio       8600        200      0.633      0.805      0.801      0.753\n","             saxophone       8600        200      0.643      0.705      0.732      0.723\n","                  shoe       8600        200      0.624      0.665      0.675      0.655\n","            skateboard       8600        200      0.672        0.9       0.91      0.859\n","                  sock       8600        200      0.692      0.596       0.68      0.658\n","                 spoon       8600        200      0.595      0.595      0.673      0.662\n","                 stove       8600        200      0.618      0.705      0.697      0.643\n","            strawberry       8600        200      0.738       0.91      0.902      0.885\n","                 table       8600        200      0.732       0.77      0.823      0.786\n","             telephone       8600        200      0.629     0.0425      0.321      0.308\n","            television       8600        200      0.722      0.795      0.834       0.81\n","            toothbrush       8600        200      0.593       0.66      0.686      0.666\n","              umbrella       8600        200      0.921      0.885      0.936      0.903\n","                  vase       8600        200      0.771       0.69      0.794      0.782\n","                violin       8600        200      0.521      0.255      0.479      0.473\n","            watermelon       8600        200      0.625      0.685      0.719       0.68\n","Speed: 0.2ms preprocess, 0.7ms inference, 0.0ms loss, 1.0ms postprocess per image\n","Results saved to \u001b[1mruns/detect/single_model2\u001b[0m\n","ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/train\n"]}],"source":["# Train YOLOv8n on our data for 3 epochs\n","%cd /content/drive/MyDrive/capstone/colab\n","!yolo train \\\n","  model=YOLOv8/yolov8n/yolov8n.pt \\\n","  data=data/data.yml \\\n","  epochs=3 \\\n","  imgsz=640 \\\n","  name=\"single_model\"\n"]},{"cell_type":"markdown","metadata":{"id":"7dQH25x74fPj"},"source":["## 10 epochs"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1941132,"status":"ok","timestamp":1698033001398,"user":{"displayName":"Cynthia Cheng","userId":"11720369831058397288"},"user_tz":420},"id":"jAX6M0JF4R9G","outputId":"308824a4-6692-4f7e-9eff-b11d6e1ad6d5"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/.shortcut-targets-by-id/1xXZ2ldeRl7gFnlMnyoptyZpnfIdhf68X/capstone/colab\n","Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.1.0+cu118 CUDA:0 (Tesla V100-SXM2-16GB, 16151MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=YOLOv8/yolov8/yolov8n.pt, data=data/data.yml, epochs=10, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=single_model_updated, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/single_model_updated\n","Overriding model.yaml nc=80 with nc=43\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n","  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n","  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n","  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n"," 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n"," 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 22        [15, 18, 21]  1    759697  ultralytics.nn.modules.head.Detect           [43, [64, 128, 256]]          \n","Model summary: 225 layers, 3019233 parameters, 3019217 gradients, 8.2 GFLOPs\n","\n","Transferred 319/355 items from pretrained weights\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/single_model_updated', view at http://localhost:6006/\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/.shortcut-targets-by-id/1xXZ2ldeRl7gFnlMnyoptyZpnfIdhf68X/capstone/colab/data/train/labels/apple.cache... 30100 images, 0 backgrounds, 0 corrupt: 100% 30100/30100 [00:00<?, ?it/s]\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/.shortcut-targets-by-id/1xXZ2ldeRl7gFnlMnyoptyZpnfIdhf68X/capstone/colab/data/valid/labels/apple.cache... 8600 images, 0 backgrounds, 0 corrupt: 100% 8600/8600 [00:00<?, ?it/s]\n","Plotting labels to runs/detect/single_model_updated/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000213, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1mruns/detect/single_model_updated\u001b[0m\n","Starting training for 10 epochs...\n","Closing dataloader mosaic\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       1/10      2.42G     0.2442       3.52      1.084          4        640: 100% 1882/1882 [44:16<00:00,  1.41s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 269/269 [01:49<00:00,  2.45it/s]\n","                   all       8600       8600       0.67      0.638      0.691      0.691\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       2/10      2.45G    0.06108      1.739     0.9206          4        640: 100% 1882/1882 [03:09<00:00,  9.92it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 269/269 [00:43<00:00,  6.20it/s]\n","                   all       8600       8600      0.733      0.747      0.807      0.807\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       3/10      2.45G    0.05135      1.263     0.9088          4        640: 100% 1882/1882 [03:03<00:00, 10.27it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 269/269 [00:41<00:00,  6.44it/s]\n","                   all       8600       8600      0.826       0.78      0.856      0.856\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       4/10      2.45G    0.04359      1.013     0.9042          4        640: 100% 1882/1882 [02:55<00:00, 10.71it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 269/269 [00:40<00:00,  6.63it/s]\n","                   all       8600       8600      0.831      0.802      0.873      0.872\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       5/10      2.45G    0.03921       0.86     0.9019          4        640: 100% 1882/1882 [02:59<00:00, 10.49it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 269/269 [00:41<00:00,  6.49it/s]\n","                   all       8600       8600      0.845      0.814      0.887      0.887\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       6/10      2.45G     0.0341     0.7359     0.8999          4        640: 100% 1882/1882 [02:59<00:00, 10.50it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 269/269 [00:40<00:00,  6.57it/s]\n","                   all       8600       8600      0.873      0.824      0.899      0.899\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       7/10      2.45G     0.0297     0.6432     0.8974          4        640: 100% 1882/1882 [02:57<00:00, 10.58it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 269/269 [00:40<00:00,  6.67it/s]\n","                   all       8600       8600      0.873      0.839      0.908      0.908\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       8/10      2.45G    0.02631     0.5794     0.8971          4        640: 100% 1882/1882 [03:01<00:00, 10.36it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 269/269 [00:41<00:00,  6.48it/s]\n","                   all       8600       8600      0.881      0.836      0.911      0.911\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       9/10      2.45G    0.02344     0.5206     0.8984          4        640: 100% 1882/1882 [03:02<00:00, 10.30it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 269/269 [00:40<00:00,  6.59it/s]\n","                   all       8600       8600      0.878      0.852      0.917      0.917\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      10/10      2.45G    0.02088     0.4704      0.897          4        640: 100% 1882/1882 [02:57<00:00, 10.58it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 269/269 [00:41<00:00,  6.54it/s]\n","                   all       8600       8600      0.884      0.864      0.922      0.922\n","\n","10 epochs completed in 1.327 hours.\n","Optimizer stripped from runs/detect/single_model_updated/weights/last.pt, 6.3MB\n","Optimizer stripped from runs/detect/single_model_updated/weights/best.pt, 6.3MB\n","\n","Validating runs/detect/single_model_updated/weights/best.pt...\n","Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.1.0+cu118 CUDA:0 (Tesla V100-SXM2-16GB, 16151MiB)\n","Model summary (fused): 168 layers, 3014033 parameters, 0 gradients, 8.1 GFLOPs\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 269/269 [00:43<00:00,  6.12it/s]\n","                   all       8600       8600      0.884      0.864      0.922      0.922\n","                 apple       8600        200       0.95      0.946      0.984      0.984\n","              backpack       8600        200      0.891      0.816      0.917      0.917\n","                banana       8600        200      0.851      0.905      0.926      0.926\n","            basketball       8600        200      0.861       0.87      0.916      0.916\n","                   bed       8600        200      0.884       0.78      0.874      0.874\n","               bicycle       8600        200      0.938       0.97      0.989      0.989\n","                  book       8600        200      0.856      0.905      0.939      0.939\n","                bucket       8600        200      0.939        0.9      0.963      0.963\n","                  cake       8600        200      0.947      0.895      0.951      0.951\n","              calendar       8600        200      0.803      0.813      0.864      0.864\n","                 chair       8600        200      0.901      0.913      0.962      0.962\n","                 clock       8600        200      0.974      0.935      0.976      0.976\n","                 couch       8600        200      0.859      0.895      0.941      0.941\n","                   dog       8600        200       0.87      0.738       0.88       0.88\n","              dumbbell       8600        200       0.87      0.805      0.899      0.899\n","            eyeglasses       8600        200      0.902      0.915      0.941      0.941\n","                   fan       8600        200      0.874      0.855      0.933      0.933\n","                guitar       8600        200      0.704       0.65      0.731      0.731\n","                   hat       8600        200      0.906      0.875       0.94       0.94\n","                jacket       8600        200      0.963      0.899      0.953      0.953\n","                   key       8600        200       0.85      0.855       0.93       0.93\n","                laptop       8600        200      0.946      0.784      0.926      0.926\n","                 pants       8600        200      0.964      0.933       0.95       0.95\n","                pencil       8600        200      0.857      0.915      0.951      0.951\n","                 piano       8600        200      0.859      0.745      0.826      0.826\n","                pillow       8600        200      0.904      0.845      0.916      0.916\n","                rabbit       8600        200       0.86       0.91      0.954      0.954\n","                 radio       8600        200      0.953      0.903      0.943      0.943\n","             saxophone       8600        200      0.933      0.841      0.914      0.914\n","                  shoe       8600        200      0.864       0.87      0.935      0.935\n","            skateboard       8600        200      0.933       0.97      0.985      0.985\n","                  sock       8600        200      0.867       0.82      0.899      0.899\n","                 spoon       8600        200      0.922      0.835      0.917      0.917\n","                 stove       8600        200      0.866       0.83      0.908      0.908\n","            strawberry       8600        200      0.883      0.945       0.96       0.96\n","                 table       8600        200       0.87      0.915      0.923      0.923\n","             telephone       8600        200      0.845       0.81      0.892      0.892\n","            television       8600        200      0.891      0.902       0.95       0.95\n","            toothbrush       8600        200      0.857       0.89      0.921      0.921\n","              umbrella       8600        200      0.977      0.965      0.978      0.978\n","                  vase       8600        200      0.879      0.895      0.944      0.944\n","                violin       8600        200      0.656      0.666      0.739      0.739\n","            watermelon       8600        200      0.838      0.829      0.907      0.907\n","Speed: 0.1ms preprocess, 0.7ms inference, 0.0ms loss, 0.8ms postprocess per image\n","Results saved to \u001b[1mruns/detect/single_model_updated\u001b[0m\n","ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/train\n"]}],"source":["# Train previous model for another 10 epochs\n","%cd /content/drive/MyDrive/capstone/colab\n","!yolo train \\\n","  model=YOLOv8/yolov8/yolov8n.pt \\\n","  data=data/data.yml \\\n","  epochs=10 \\\n","  imgsz=640 \\\n","  name=\"single_model_updated\""]},{"cell_type":"markdown","metadata":{"id":"lUHlnWPmtshH"},"source":["## another 10 epochs"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"jDATuRy1treC","outputId":"7ce49011-0bbc-4855-bdb8-4c0821c9829d"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/.shortcut-targets-by-id/1xXZ2ldeRl7gFnlMnyoptyZpnfIdhf68X/capstone/colab\n","Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.1.0+cu118 CUDA:0 (Tesla V100-SXM2-16GB, 16151MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=runs/detect/single_model_updated/weights/last.pt, data=data/data.yml, epochs=10, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=single_model_updated2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/single_model_updated2\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n","  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n","  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n","  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n"," 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n"," 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 22        [15, 18, 21]  1    759697  ultralytics.nn.modules.head.Detect           [43, [64, 128, 256]]          \n","Model summary: 225 layers, 3019233 parameters, 3019217 gradients, 8.2 GFLOPs\n","\n","Transferred 355/355 items from pretrained weights\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/single_model_updated2', view at http://localhost:6006/\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/.shortcut-targets-by-id/1xXZ2ldeRl7gFnlMnyoptyZpnfIdhf68X/capstone/colab/data/train/labels/apple.cache... 30100 images, 0 backgrounds, 0 corrupt: 100% 30100/30100 [00:00<?, ?it/s]\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/.shortcut-targets-by-id/1xXZ2ldeRl7gFnlMnyoptyZpnfIdhf68X/capstone/colab/data/valid/labels/apple.cache... 8600 images, 0 backgrounds, 0 corrupt: 100% 8600/8600 [00:00<?, ?it/s]\n","Plotting labels to runs/detect/single_model_updated2/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000213, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1mruns/detect/single_model_updated2\u001b[0m\n","Starting training for 10 epochs...\n","Closing dataloader mosaic\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       1/10      2.42G    0.02165     0.4616     0.8965          4        640: 100% 1882/1882 [03:20<00:00,  9.40it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 269/269 [00:42<00:00,  6.29it/s]\n","                   all       8600       8600      0.877      0.842      0.913      0.913\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       2/10      2.45G    0.02696     0.5123     0.8991          4        640: 100% 1882/1882 [03:12<00:00,  9.80it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 269/269 [00:42<00:00,  6.31it/s]\n","                   all       8600       8600      0.873      0.838      0.909      0.909\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       3/10      2.45G    0.02995     0.5262     0.8976          4        640: 100% 1882/1882 [03:09<00:00,  9.94it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 269/269 [00:41<00:00,  6.46it/s]\n","                   all       8600       8600      0.868      0.845      0.909      0.909\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       4/10      2.45G    0.02838      0.505     0.8973          4        640: 100% 1882/1882 [03:04<00:00, 10.23it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 269/269 [00:41<00:00,  6.43it/s]\n","                   all       8600       8600      0.872      0.843       0.91       0.91\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       5/10      2.45G    0.02783     0.4804     0.8974          4        640: 100% 1882/1882 [03:01<00:00, 10.36it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 269/269 [00:40<00:00,  6.57it/s]\n","                   all       8600       8600      0.867      0.838      0.908      0.908\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       6/10      2.45G    0.02559     0.4389      0.897          4        640: 100% 1882/1882 [02:59<00:00, 10.49it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 269/269 [00:41<00:00,  6.51it/s]\n","                   all       8600       8600      0.877      0.853      0.917      0.917\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       7/10      2.45G    0.02324     0.4012     0.8955          4        640: 100% 1882/1882 [02:58<00:00, 10.52it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 269/269 [00:41<00:00,  6.52it/s]\n","                   all       8600       8600      0.893       0.85      0.918      0.918\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       8/10      2.45G    0.02118     0.3711     0.8957          4        640: 100% 1882/1882 [03:02<00:00, 10.31it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 269/269 [00:41<00:00,  6.44it/s]\n","                   all       8600       8600      0.885      0.861      0.922      0.922\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       9/10      2.45G        inf     0.3345     0.8974          4        640: 100% 1882/1882 [03:03<00:00, 10.26it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 269/269 [00:40<00:00,  6.64it/s]\n","                   all       8600       8600      0.903      0.854      0.926      0.926\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      10/10      2.44G    0.01744     0.3036     0.8965          4        640: 100% 1882/1882 [03:00<00:00, 10.43it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 269/269 [00:40<00:00,  6.63it/s]\n","                   all       8600       8600      0.888      0.872      0.927      0.927\n","\n","10 epochs completed in 0.632 hours.\n","Optimizer stripped from runs/detect/single_model_updated2/weights/last.pt, 6.3MB\n","Optimizer stripped from runs/detect/single_model_updated2/weights/best.pt, 6.3MB\n","\n","Validating runs/detect/single_model_updated2/weights/best.pt...\n","Ultralytics YOLOv8.0.200 ðŸš€ Python-3.10.12 torch-2.1.0+cu118 CUDA:0 (Tesla V100-SXM2-16GB, 16151MiB)\n","Model summary (fused): 168 layers, 3014033 parameters, 0 gradients, 8.1 GFLOPs\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 269/269 [00:43<00:00,  6.13it/s]\n","                   all       8600       8600      0.888      0.872      0.927      0.927\n","                 apple       8600        200      0.969       0.93      0.975      0.975\n","              backpack       8600        200      0.912      0.825      0.921      0.921\n","                banana       8600        200       0.87      0.907      0.926      0.926\n","            basketball       8600        200      0.839       0.89      0.928      0.928\n","                   bed       8600        200      0.884      0.804       0.89       0.89\n","               bicycle       8600        200       0.95      0.947      0.989      0.989\n","                  book       8600        200      0.866      0.901      0.951      0.951\n","                bucket       8600        200      0.956      0.905      0.961      0.961\n","                  cake       8600        200      0.926      0.905      0.951      0.951\n","              calendar       8600        200      0.793      0.835       0.87       0.87\n","                 chair       8600        200      0.914       0.92      0.956      0.956\n","                 clock       8600        200       0.98      0.961      0.973      0.973\n","                 couch       8600        200      0.833       0.92      0.943      0.943\n","                   dog       8600        200      0.864       0.77      0.895      0.895\n","              dumbbell       8600        200      0.895      0.785      0.899      0.899\n","            eyeglasses       8600        200      0.861      0.915      0.945      0.945\n","                   fan       8600        200      0.854      0.885      0.939      0.939\n","                guitar       8600        200      0.729      0.593      0.726      0.726\n","                   hat       8600        200      0.889      0.882      0.945      0.945\n","                jacket       8600        200      0.929      0.916      0.958      0.958\n","                   key       8600        200      0.879       0.89      0.937      0.937\n","                laptop       8600        200      0.941      0.798      0.923      0.923\n","                 pants       8600        200      0.942      0.925      0.954      0.954\n","                pencil       8600        200       0.86      0.935      0.952      0.952\n","                 piano       8600        200      0.842      0.755       0.84       0.84\n","                pillow       8600        200      0.924      0.845      0.919      0.919\n","                rabbit       8600        200      0.886      0.895      0.949      0.949\n","                 radio       8600        200      0.932      0.915      0.949      0.949\n","             saxophone       8600        200      0.939       0.86      0.917      0.917\n","                  shoe       8600        200      0.865      0.898      0.946      0.946\n","            skateboard       8600        200      0.955      0.964      0.987      0.987\n","                  sock       8600        200      0.883      0.831      0.904      0.904\n","                 spoon       8600        200      0.918      0.837      0.919      0.919\n","                 stove       8600        200        0.8       0.87      0.912      0.912\n","            strawberry       8600        200      0.917      0.943       0.96       0.96\n","                 table       8600        200       0.89       0.91      0.925      0.925\n","             telephone       8600        200      0.878      0.825      0.903      0.903\n","            television       8600        200      0.925      0.923      0.961      0.961\n","            toothbrush       8600        200      0.916      0.865      0.931      0.931\n","              umbrella       8600        200      0.964      0.955      0.982      0.982\n","                  vase       8600        200      0.882      0.875      0.942      0.942\n","                violin       8600        200      0.693      0.744      0.778      0.778\n","            watermelon       8600        200      0.837      0.855      0.922      0.922\n","Speed: 0.2ms preprocess, 0.7ms inference, 0.0ms loss, 0.8ms postprocess per image\n","Results saved to \u001b[1mruns/detect/single_model_updated2\u001b[0m\n","ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/train\n"]}],"source":["# Train previous model for another 10 epochs\n","%cd /content/drive/MyDrive/capstone/colab\n","!yolo train \\\n","  model=runs/detect/single_model_updated/weights/last.pt \\\n","  data=data/data.yml \\\n","  epochs=10 \\\n","  imgsz=640 \\\n","  name=\"single_model_updated2\""]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
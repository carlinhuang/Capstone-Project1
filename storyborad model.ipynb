{"cells":[{"cell_type":"markdown","metadata":{"id":"V1wAb73JiKeu"},"source":["## install dependencies"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12229,"status":"ok","timestamp":1701659941101,"user":{"displayName":"Cynthia Cheng","userId":"11720369831058397288"},"user_tz":480},"id":"73ItWBcDfRiS","outputId":"ee9e2af7-6e46-4e2e-bb7f-c42d363d6afe"},"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics YOLOv8.0.222 🚀 Python-3.10.12 torch-2.1.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n","Setup complete ✅ (8 CPUs, 51.0 GB RAM, 26.9/166.8 GB disk)\n"]}],"source":["%pip install ultralytics\n","import ultralytics\n","ultralytics.checks()\n","import os"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":79979,"status":"ok","timestamp":1701660252206,"user":{"displayName":"Cynthia Cheng","userId":"11720369831058397288"},"user_tz":480},"id":"fbTvoEqafWHy","outputId":"8acfd39a-29ff-482f-d2bf-f5c52b094d64"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1701583433944,"user":{"displayName":"Xiaoyu","userId":"15385861848997838893"},"user_tz":480},"id":"0RHxX_z6fykS","outputId":"27e1f195-28a6-4cd4-b5ef-95110050cd9e"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/capstone/colab\n"]},{"output_type":"execute_result","data":{"text/plain":["'/content/drive/MyDrive/capstone/colab'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":3}],"source":["%cd /content/drive/MyDrive/capstone/colab\n","%pwd"]},{"cell_type":"markdown","metadata":{"id":"qNrDYVXAiPXF"},"source":["## file check"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":130451,"status":"ok","timestamp":1700952311596,"user":{"displayName":"Cynthia Cheng","userId":"11720369831058397288"},"user_tz":480},"id":"orQ5TF5JgOHZ","outputId":"a5da6a09-f67b-4add-bbbd-74ff123a8dbe"},"outputs":[{"output_type":"stream","name":"stdout","text":["training labels 7311\n","training images 7311\n","validation labels 1798\n","validation images 1798\n","testing labels 971\n","testing images 971\n","training % 0.725297619047619\n","validation % 0.17837301587301588\n","test % 0.09632936507936508\n"]}],"source":["import os\n","#file check\n","path = '/content/drive/MyDrive/capstone/colab/storyboards/v3/'\n","s1 = len(os.listdir(path+\"train/labels\"))\n","s2 = len(os.listdir(path+\"train/images\"))\n","print(\"training labels\",s1)\n","print(\"training images\",s2)\n","\n","s3 = len(os.listdir(path+\"valid/labels\"))\n","s4 = len(os.listdir(path+\"valid/images\"))\n","print(\"validation labels\",s3)\n","print(\"validation images\",s4)\n","\n","s5 = len(os.listdir(path+\"test/labels\"))\n","s6 = len(os.listdir(path+\"test/images\"))\n","print(\"testing labels\",s5)\n","print(\"testing images\",s6)\n","print(\"training %\", s1/(s1+s3+s5))\n","print(\"validation %\",s3/(s1+s3+s5))\n","print(\"test %\", s5/(s1+s3+s5))"]},{"cell_type":"markdown","metadata":{"id":"K_LUKAwniRz4"},"source":["## model training (storyborad without overlap)"]},{"cell_type":"markdown","source":["### use single model as pre-trained weight"],"metadata":{"id":"RT0sSqreMGsZ"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"SnBmwa_HiRPp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698543317457,"user_tz":420,"elapsed":1109808,"user":{"displayName":"Zhuohang Li","userId":"00155514878023331603"}},"outputId":"65600c2a-3553-4d9b-b2ac-7741cdc7d904"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/.shortcut-targets-by-id/1xXZ2ldeRl7gFnlMnyoptyZpnfIdhf68X/capstone/colab\n","Ultralytics YOLOv8.0.202 🚀 Python-3.10.12 torch-2.1.0+cu118 CUDA:0 (NVIDIA A100-SXM4-40GB, 40514MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=runs/detect/single_model_updated2/weights/best.pt, data=storyboards/v1/storyboard.yml, epochs=3, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=storyboard_model1, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/storyboard_model1\n","Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n","100% 755k/755k [00:00<00:00, 139MB/s]\n","2023-10-29 01:16:58.151593: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2023-10-29 01:16:58.151648: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2023-10-29 01:16:58.151692: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n","  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n","  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n","  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n"," 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n"," 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 22        [15, 18, 21]  1    759697  ultralytics.nn.modules.head.Detect           [43, [64, 128, 256]]          \n","Model summary: 225 layers, 3019233 parameters, 3019217 gradients, 8.2 GFLOPs\n","\n","Transferred 355/355 items from pretrained weights\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/storyboard_model1', view at http://localhost:6006/\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/.shortcut-targets-by-id/1xXZ2ldeRl7gFnlMnyoptyZpnfIdhf68X/capstone/colab/storyboards/v1/train/labels... 5891 images, 0 backgrounds, 0 corrupt: 100% 5891/5891 [11:18<00:00,  8.68it/s]\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/drive/.shortcut-targets-by-id/1xXZ2ldeRl7gFnlMnyoptyZpnfIdhf68X/capstone/colab/storyboards/v1/train/labels.cache\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/.shortcut-targets-by-id/1xXZ2ldeRl7gFnlMnyoptyZpnfIdhf68X/capstone/colab/storyboards/v1/valid/labels... 1967 images, 0 backgrounds, 0 corrupt: 100% 1967/1967 [03:44<00:00,  8.75it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/drive/.shortcut-targets-by-id/1xXZ2ldeRl7gFnlMnyoptyZpnfIdhf68X/capstone/colab/storyboards/v1/valid/labels.cache\n","Plotting labels to runs/detect/storyboard_model1/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000213, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1mruns/detect/storyboard_model1\u001b[0m\n","Starting training for 3 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","        1/3      2.38G      1.557      4.393      1.213         27        640: 100% 369/369 [00:38<00:00,  9.49it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 62/62 [00:12<00:00,  5.11it/s]\n","                   all       1967       8234     0.0207          1     0.0291     0.0266\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","        2/3      2.42G      0.475      2.734     0.8337         14        640: 100% 369/369 [00:33<00:00, 10.97it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 62/62 [00:10<00:00,  5.66it/s]\n","                   all       1967       8234     0.0227          1       0.03     0.0284\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","        3/3      2.41G     0.4343      2.661     0.8267         14        640: 100% 369/369 [00:33<00:00, 11.05it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 62/62 [00:10<00:00,  5.73it/s]\n","                   all       1967       8234     0.0229          1     0.0298     0.0283\n","\n","3 epochs completed in 0.040 hours.\n","Optimizer stripped from runs/detect/storyboard_model1/weights/last.pt, 6.3MB\n","Optimizer stripped from runs/detect/storyboard_model1/weights/best.pt, 6.3MB\n","\n","Validating runs/detect/storyboard_model1/weights/best.pt...\n","Ultralytics YOLOv8.0.202 🚀 Python-3.10.12 torch-2.1.0+cu118 CUDA:0 (NVIDIA A100-SXM4-40GB, 40514MiB)\n","Model summary (fused): 168 layers, 3014033 parameters, 0 gradients, 8.1 GFLOPs\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 62/62 [00:12<00:00,  4.80it/s]\n","                   all       1967       8234     0.0227          1       0.03     0.0285\n","                 apple       1967        196     0.0232          1     0.0432     0.0416\n","              backpack       1967        190     0.0225          1     0.0455     0.0441\n","                banana       1967        199     0.0235          1     0.0241      0.023\n","            basketball       1967        182     0.0213          1     0.0548     0.0529\n","                   bed       1967        167     0.0198          1     0.0218     0.0204\n","               bicycle       1967        199     0.0236          1     0.0266      0.025\n","                  book       1967        175     0.0207          1     0.0282      0.027\n","                bucket       1967        200     0.0237          1     0.0474     0.0451\n","                  cake       1967        179     0.0212          1     0.0275     0.0265\n","              calendar       1967        191     0.0226          1     0.0387     0.0367\n","                 chair       1967        211      0.025          1     0.0255      0.024\n","                 clock       1967        199     0.0236          1     0.0569     0.0555\n","                 couch       1967        185     0.0219          1     0.0365     0.0342\n","                   dog       1967        171     0.0203          1      0.023     0.0219\n","              dumbbell       1967        196     0.0232          1      0.024     0.0221\n","            eyeglasses       1967        204     0.0241          1     0.0253     0.0233\n","                   fan       1967        203     0.0241          1     0.0318     0.0305\n","                guitar       1967        180     0.0213          1     0.0219     0.0207\n","                   hat       1967        174     0.0206          1     0.0254     0.0242\n","                jacket       1967        187     0.0221          1     0.0259     0.0246\n","                   key       1967        196     0.0232          1     0.0237      0.022\n","                laptop       1967        179     0.0212          1     0.0289     0.0279\n","                 pants       1967        181     0.0214          1     0.0394     0.0379\n","                pencil       1967        198     0.0233          1     0.0238     0.0211\n","                 piano       1967        195     0.0231          1     0.0281     0.0264\n","                pillow       1967        211     0.0249          1     0.0339     0.0324\n","                rabbit       1967        171     0.0201      0.994     0.0223     0.0214\n","                 radio       1967        210     0.0249          1     0.0312     0.0297\n","             saxophone       1967        204     0.0242          1     0.0253     0.0243\n","                  shoe       1967        180     0.0213          1     0.0257     0.0242\n","            skateboard       1967        210     0.0248          1     0.0254      0.023\n","                  sock       1967        207     0.0245          1     0.0279     0.0269\n","                 spoon       1967        190     0.0224      0.995     0.0229     0.0208\n","                 stove       1967        197     0.0233          1     0.0292      0.028\n","            strawberry       1967        186      0.022          1     0.0373     0.0355\n","                 table       1967        190     0.0225          1     0.0243     0.0229\n","             telephone       1967        182     0.0215          1     0.0292      0.028\n","            television       1967        184     0.0218          1     0.0314     0.0299\n","            toothbrush       1967        206     0.0244          1     0.0251     0.0218\n","              umbrella       1967        204     0.0242          1     0.0267     0.0255\n","                  vase       1967        195     0.0231          1     0.0238     0.0225\n","                violin       1967        186      0.022          1     0.0226     0.0213\n","            watermelon       1967        184     0.0217          1     0.0295      0.028\n","Speed: 0.1ms preprocess, 0.5ms inference, 0.0ms loss, 2.0ms postprocess per image\n","Results saved to \u001b[1mruns/detect/storyboard_model1\u001b[0m\n","💡 Learn more at https://docs.ultralytics.com/modes/train\n"]}],"source":["# Train a new storyboard model on storyboard data for 3 epochs\n","%cd /content/drive/MyDrive/capstone/colab\n","!yolo train \\\n","  model= runs/detect/single_model_updated2/weights/best.pt \\\n","  data=storyboards/v1/storyboard.yml \\\n","  epochs=3 \\\n","  imgsz=640 \\\n","  name=\"storyboard_model1\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2Drkrj-ii4Ru","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698546773189,"user_tz":420,"elapsed":775809,"user":{"displayName":"Zhuohang Li","userId":"00155514878023331603"}},"outputId":"5c186b14-162c-4d50-b754-2e059dbc3743"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/.shortcut-targets-by-id/1xXZ2ldeRl7gFnlMnyoptyZpnfIdhf68X/capstone/colab\n","Ultralytics YOLOv8.0.202 🚀 Python-3.10.12 torch-2.1.0+cu118 CUDA:0 (NVIDIA A100-SXM4-40GB, 40514MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=runs/detect/storyboard_model1/weights/last.pt, data=storyboards/v1/storyboard.yml, epochs=10, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=storyboard_model2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/storyboard_model2\n","Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n","100% 755k/755k [00:00<00:00, 127MB/s]\n","2023-10-29 02:20:04.891857: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2023-10-29 02:20:04.891907: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2023-10-29 02:20:04.891946: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n","  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n","  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n","  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n"," 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n"," 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 22        [15, 18, 21]  1    759697  ultralytics.nn.modules.head.Detect           [43, [64, 128, 256]]          \n","Model summary: 225 layers, 3019233 parameters, 3019217 gradients, 8.2 GFLOPs\n","\n","Transferred 355/355 items from pretrained weights\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/storyboard_model2', view at http://localhost:6006/\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/.shortcut-targets-by-id/1xXZ2ldeRl7gFnlMnyoptyZpnfIdhf68X/capstone/colab/storyboards/v1/train/labels.cache... 5891 images, 0 backgrounds, 0 corrupt: 100% 5891/5891 [00:00<?, ?it/s]\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/.shortcut-targets-by-id/1xXZ2ldeRl7gFnlMnyoptyZpnfIdhf68X/capstone/colab/storyboards/v1/valid/labels.cache... 1967 images, 0 backgrounds, 0 corrupt: 100% 1967/1967 [00:00<?, ?it/s]\n","Plotting labels to runs/detect/storyboard_model2/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000213, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1mruns/detect/storyboard_model2\u001b[0m\n","Starting training for 10 epochs...\n","Closing dataloader mosaic\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       1/10      2.37G     0.3678      2.591     0.8041         10        640: 100% 369/369 [00:38<00:00,  9.48it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 62/62 [01:44<00:00,  1.69s/it]\n","                   all       1967       8234     0.0231          1     0.0294      0.028\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       2/10       2.4G     0.3585      2.554     0.8028         10        640: 100% 369/369 [00:33<00:00, 11.10it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 62/62 [00:10<00:00,  5.87it/s]\n","                   all       1967       8234     0.0231          1     0.0294     0.0282\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       3/10      2.39G     0.3396      2.522     0.7978          9        640: 100% 369/369 [00:32<00:00, 11.31it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 62/62 [00:10<00:00,  5.91it/s]\n","                   all       1967       8234     0.0232          1     0.0291     0.0281\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       4/10       2.4G      0.323        2.5     0.7986         10        640: 100% 369/369 [00:31<00:00, 11.64it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 62/62 [00:10<00:00,  5.95it/s]\n","                   all       1967       8234     0.0232          1     0.0289      0.028\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       5/10       2.4G     0.3151      2.489     0.7966          9        640: 100% 369/369 [00:32<00:00, 11.52it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 62/62 [00:10<00:00,  6.02it/s]\n","                   all       1967       8234     0.0232          1     0.0295     0.0287\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       6/10       2.4G      0.303      2.479     0.7965          9        640: 100% 369/369 [00:32<00:00, 11.47it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 62/62 [00:10<00:00,  5.97it/s]\n","                   all       1967       8234     0.0232          1     0.0281     0.0274\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       7/10      2.39G     0.2918      2.472     0.7933          9        640: 100% 369/369 [00:32<00:00, 11.48it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 62/62 [00:10<00:00,  5.93it/s]\n","                   all       1967       8234     0.0232          1     0.0295     0.0288\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       8/10       2.4G     0.2827      2.465     0.7909          9        640: 100% 369/369 [00:32<00:00, 11.41it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 62/62 [00:10<00:00,  5.86it/s]\n","                   all       1967       8234     0.0232          1       0.03     0.0293\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       9/10       2.4G     0.2767      2.463     0.7962         11        640: 100% 369/369 [00:32<00:00, 11.46it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 62/62 [00:10<00:00,  5.90it/s]\n","                   all       1967       8234     0.0232          1     0.0294     0.0288\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      10/10       2.4G     0.2714       2.46     0.7942         11        640: 100% 369/369 [00:31<00:00, 11.57it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 62/62 [00:10<00:00,  5.87it/s]\n","                   all       1967       8234     0.0232          1       0.03     0.0294\n","\n","10 epochs completed in 0.150 hours.\n","Optimizer stripped from runs/detect/storyboard_model2/weights/last.pt, 6.3MB\n","Optimizer stripped from runs/detect/storyboard_model2/weights/best.pt, 6.3MB\n","\n","Validating runs/detect/storyboard_model2/weights/best.pt...\n","Ultralytics YOLOv8.0.202 🚀 Python-3.10.12 torch-2.1.0+cu118 CUDA:0 (NVIDIA A100-SXM4-40GB, 40514MiB)\n","Model summary (fused): 168 layers, 3014033 parameters, 0 gradients, 8.1 GFLOPs\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 62/62 [00:12<00:00,  5.01it/s]\n","                   all       1967       8234     0.0232          1     0.0304     0.0298\n","                 apple       1967        196     0.0237          1     0.0462     0.0458\n","              backpack       1967        190      0.023          1     0.0437     0.0434\n","                banana       1967        199     0.0241          1     0.0252     0.0249\n","            basketball       1967        182     0.0221          1     0.0568     0.0553\n","                   bed       1967        167     0.0202          1     0.0208     0.0204\n","               bicycle       1967        199     0.0241          1     0.0256     0.0251\n","                  book       1967        175     0.0212          1     0.0329     0.0325\n","                bucket       1967        200     0.0242          1     0.0438     0.0428\n","                  cake       1967        179     0.0217          1     0.0333     0.0322\n","              calendar       1967        191     0.0231          1     0.0399     0.0394\n","                 chair       1967        211     0.0256          1      0.027     0.0262\n","                 clock       1967        199     0.0241          1     0.0595     0.0588\n","                 couch       1967        185     0.0224          1      0.026     0.0257\n","                   dog       1967        171     0.0207          1     0.0251     0.0246\n","              dumbbell       1967        196     0.0237          1     0.0238     0.0231\n","            eyeglasses       1967        204     0.0247          1     0.0247     0.0239\n","                   fan       1967        203     0.0246          1     0.0327     0.0319\n","                guitar       1967        180     0.0218          1      0.022     0.0216\n","                   hat       1967        174     0.0211          1     0.0218     0.0215\n","                jacket       1967        187     0.0227          1     0.0431     0.0427\n","                   key       1967        196     0.0237          1      0.024     0.0234\n","                laptop       1967        179     0.0217          1     0.0345     0.0336\n","                 pants       1967        181     0.0219          1     0.0311     0.0306\n","                pencil       1967        198      0.024          1     0.0239     0.0224\n","                 piano       1967        195     0.0236          1     0.0238     0.0234\n","                pillow       1967        211     0.0256          1      0.029     0.0286\n","                rabbit       1967        171     0.0207          1     0.0244     0.0239\n","                 radio       1967        210     0.0254          1     0.0288     0.0283\n","             saxophone       1967        204     0.0247          1     0.0262     0.0258\n","                  shoe       1967        180     0.0218          1     0.0224      0.022\n","            skateboard       1967        210     0.0254          1     0.0255     0.0246\n","                  sock       1967        207     0.0251          1     0.0293     0.0289\n","                 spoon       1967        190      0.023          1     0.0231     0.0219\n","                 stove       1967        197     0.0239          1     0.0343      0.034\n","            strawberry       1967        186     0.0225          1     0.0333     0.0324\n","                 table       1967        190      0.023          1     0.0235     0.0229\n","             telephone       1967        182      0.022          1     0.0266     0.0261\n","            television       1967        184     0.0223          1      0.031     0.0304\n","            toothbrush       1967        206     0.0249          1     0.0249     0.0229\n","              umbrella       1967        204     0.0247          1     0.0324     0.0319\n","                  vase       1967        195     0.0236          1     0.0296     0.0291\n","                violin       1967        186     0.0225          1     0.0232     0.0228\n","            watermelon       1967        184     0.0223          1     0.0298     0.0294\n","Speed: 0.1ms preprocess, 0.5ms inference, 0.0ms loss, 1.8ms postprocess per image\n","Results saved to \u001b[1mruns/detect/storyboard_model2\u001b[0m\n","💡 Learn more at https://docs.ultralytics.com/modes/train\n"]}],"source":["# Continue to train storyboard models on storyboard data for another 10 epochs\n","%cd /content/drive/MyDrive/capstone/colab\n","!yolo train \\\n","  model= runs/detect/storyboard_model1/weights/last.pt \\\n","  data=storyboards/v1/storyboard.yml \\\n","  epochs=10 \\\n","  imgsz=640 \\\n","  name=\"storyboard_model2\""]},{"cell_type":"markdown","source":["### use yolov8 as pre-trained weight"],"metadata":{"id":"Zvg7kReWMPH3"}},{"cell_type":"code","source":["# Use Original YoloV8 model->epochs = 3\n","%cd /content/drive/MyDrive/capstone/colab\n","!yolo train \\\n","  model= yolov8/yolov8n.pt \\\n","  data=storyboards/v1/storyboard.yml \\\n","  epochs=3 \\\n","  imgsz=640 \\\n","  name=\"storyboard_update_model\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xh_aCkrkTJMk","executionInfo":{"status":"ok","timestamp":1698547763443,"user_tz":420,"elapsed":439200,"user":{"displayName":"Zhuohang Li","userId":"00155514878023331603"}},"outputId":"ec58230d-b530-4a4b-952d-68d0f937ba1a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/.shortcut-targets-by-id/1xXZ2ldeRl7gFnlMnyoptyZpnfIdhf68X/capstone/colab\n","Ultralytics YOLOv8.0.202 🚀 Python-3.10.12 torch-2.1.0+cu118 CUDA:0 (NVIDIA A100-SXM4-40GB, 40514MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8/yolov8n.pt, data=storyboards/v1/storyboard.yml, epochs=3, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=storyboard_update_model, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/storyboard_update_model\n","Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n","100% 755k/755k [00:00<00:00, 45.8MB/s]\n","2023-10-29 02:42:11.274642: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2023-10-29 02:42:11.274691: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2023-10-29 02:42:11.274725: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","Overriding model.yaml nc=80 with nc=43\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n","  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n","  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n","  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n"," 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n"," 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 22        [15, 18, 21]  1    759697  ultralytics.nn.modules.head.Detect           [43, [64, 128, 256]]          \n","Model summary: 225 layers, 3019233 parameters, 3019217 gradients, 8.2 GFLOPs\n","\n","Transferred 319/355 items from pretrained weights\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/storyboard_update_model', view at http://localhost:6006/\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/.shortcut-targets-by-id/1xXZ2ldeRl7gFnlMnyoptyZpnfIdhf68X/capstone/colab/storyboards/v1/train/labels.cache... 5891 images, 0 backgrounds, 0 corrupt: 100% 5891/5891 [00:00<?, ?it/s]\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/.shortcut-targets-by-id/1xXZ2ldeRl7gFnlMnyoptyZpnfIdhf68X/capstone/colab/storyboards/v1/valid/labels.cache... 1967 images, 0 backgrounds, 0 corrupt: 100% 1967/1967 [00:00<?, ?it/s]\n","Plotting labels to runs/detect/storyboard_update_model/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000213, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1mruns/detect/storyboard_update_model\u001b[0m\n","Starting training for 3 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","        1/3      2.36G     0.6794      3.634     0.8924         27        640: 100% 369/369 [00:40<00:00,  9.07it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 62/62 [00:59<00:00,  1.05it/s]\n","                   all       1967       8234      0.352      0.462      0.373      0.334\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","        2/3       2.4G     0.5359      2.352     0.8675         14        640: 100% 369/369 [00:33<00:00, 10.91it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 62/62 [00:10<00:00,  5.96it/s]\n","                   all       1967       8234      0.601      0.628      0.658      0.597\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","        3/3      2.39G     0.4918      1.896     0.8566         14        640: 100% 369/369 [00:33<00:00, 11.02it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 62/62 [00:10<00:00,  6.14it/s]\n","                   all       1967       8234      0.699      0.689       0.74      0.686\n","\n","3 epochs completed in 0.054 hours.\n","Optimizer stripped from runs/detect/storyboard_update_model/weights/last.pt, 6.3MB\n","Optimizer stripped from runs/detect/storyboard_update_model/weights/best.pt, 6.3MB\n","\n","Validating runs/detect/storyboard_update_model/weights/best.pt...\n","Ultralytics YOLOv8.0.202 🚀 Python-3.10.12 torch-2.1.0+cu118 CUDA:0 (NVIDIA A100-SXM4-40GB, 40514MiB)\n","Model summary (fused): 168 layers, 3014033 parameters, 0 gradients, 8.1 GFLOPs\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   3% 2/62 [00:00<00:13,  4.50it/s]WARNING ⚠️ NMS time limit 2.100s exceeded\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 62/62 [00:15<00:00,  3.95it/s]\n","                   all       1967       8234      0.698      0.686      0.737      0.682\n","                 apple       1967        196      0.831      0.929      0.938        0.9\n","              backpack       1967        190      0.608      0.776      0.761      0.737\n","                banana       1967        199      0.725      0.925      0.906      0.847\n","            basketball       1967        182      0.602       0.78      0.725      0.691\n","                   bed       1967        167       0.46      0.479        0.5      0.463\n","               bicycle       1967        199      0.804      0.864      0.906      0.845\n","                  book       1967        175       0.65      0.583       0.63      0.589\n","                bucket       1967        200      0.862      0.874       0.92      0.874\n","                  cake       1967        179      0.771      0.777      0.827      0.775\n","              calendar       1967        191       0.44      0.513       0.47      0.445\n","                 chair       1967        211      0.789      0.915      0.921      0.859\n","                 clock       1967        199      0.933      0.884       0.94      0.906\n","                 couch       1967        185      0.682      0.534      0.614      0.574\n","                   dog       1967        171      0.503      0.515      0.539      0.509\n","              dumbbell       1967        196      0.686      0.667      0.691      0.629\n","            eyeglasses       1967        204      0.824      0.687      0.812      0.665\n","                   fan       1967        203      0.458      0.837      0.729      0.687\n","                guitar       1967        180      0.472      0.361      0.402      0.375\n","                   hat       1967        174      0.914      0.638      0.797      0.748\n","                jacket       1967        187      0.863      0.856      0.906      0.854\n","                   key       1967        196      0.361      0.168      0.274      0.251\n","                laptop       1967        179      0.654      0.823       0.81      0.767\n","                 pants       1967        181      0.801       0.89      0.922      0.858\n","                pencil       1967        198      0.769      0.712       0.79      0.682\n","                 piano       1967        195      0.701      0.272      0.454      0.377\n","                pillow       1967        211      0.598      0.798      0.768       0.67\n","                rabbit       1967        171      0.644      0.602      0.625      0.594\n","                 radio       1967        210      0.828      0.435      0.723      0.688\n","             saxophone       1967        204      0.673      0.868      0.861      0.803\n","                  shoe       1967        180      0.649      0.667      0.711       0.63\n","            skateboard       1967        210      0.902       0.81      0.898      0.814\n","                  sock       1967        207      0.633      0.865      0.814      0.786\n","                 spoon       1967        190      0.934        0.6      0.837      0.756\n","                 stove       1967        197      0.397      0.726      0.594       0.57\n","            strawberry       1967        186      0.958      0.736      0.913      0.826\n","                 table       1967        190      0.778      0.773      0.842       0.79\n","             telephone       1967        182       0.67      0.302      0.463      0.431\n","            television       1967        184      0.718        0.9      0.915      0.868\n","            toothbrush       1967        206       0.59      0.534      0.633      0.521\n","              umbrella       1967        204      0.801      0.897      0.937      0.892\n","                  vase       1967        195      0.864      0.774       0.85      0.747\n","                violin       1967        186      0.504      0.425      0.456      0.425\n","            watermelon       1967        184      0.692      0.549      0.666      0.617\n","Speed: 0.1ms preprocess, 0.5ms inference, 0.0ms loss, 2.7ms postprocess per image\n","Results saved to \u001b[1mruns/detect/storyboard_update_model\u001b[0m\n","💡 Learn more at https://docs.ultralytics.com/modes/train\n"]}]},{"cell_type":"code","source":["# Use Original YoloV8 model->epochs = 10\n","%cd /content/drive/MyDrive/capstone/colab\n","!yolo train \\\n","  model= runs/detect/storyboard_update_model/weights/last.pt \\\n","  data=storyboards/v1/storyboard.yml \\\n","  epochs=10 \\\n","  imgsz=640 \\\n","  name=\"storyboard_update_model1\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C5xTXQ6UWNLP","executionInfo":{"status":"ok","timestamp":1698548644298,"user_tz":420,"elapsed":486746,"user":{"displayName":"Zhuohang Li","userId":"00155514878023331603"}},"outputId":"1fd8446f-a1ce-4fe1-9572-d34819184cf4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/.shortcut-targets-by-id/1xXZ2ldeRl7gFnlMnyoptyZpnfIdhf68X/capstone/colab\n","Ultralytics YOLOv8.0.202 🚀 Python-3.10.12 torch-2.1.0+cu118 CUDA:0 (NVIDIA A100-SXM4-40GB, 40514MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=runs/detect/storyboard_update_model/weights/last.pt, data=storyboards/v1/storyboard.yml, epochs=10, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=storyboard_update_model1, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/storyboard_update_model1\n","2023-10-29 02:56:00.002967: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2023-10-29 02:56:00.003026: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2023-10-29 02:56:00.003067: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n","  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n","  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n","  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n"," 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n"," 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 22        [15, 18, 21]  1    759697  ultralytics.nn.modules.head.Detect           [43, [64, 128, 256]]          \n","Model summary: 225 layers, 3019233 parameters, 3019217 gradients, 8.2 GFLOPs\n","\n","Transferred 355/355 items from pretrained weights\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/storyboard_update_model1', view at http://localhost:6006/\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/.shortcut-targets-by-id/1xXZ2ldeRl7gFnlMnyoptyZpnfIdhf68X/capstone/colab/storyboards/v1/train/labels.cache... 5891 images, 0 backgrounds, 0 corrupt: 100% 5891/5891 [00:00<?, ?it/s]\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/.shortcut-targets-by-id/1xXZ2ldeRl7gFnlMnyoptyZpnfIdhf68X/capstone/colab/storyboards/v1/valid/labels.cache... 1967 images, 0 backgrounds, 0 corrupt: 100% 1967/1967 [00:00<?, ?it/s]\n","Plotting labels to runs/detect/storyboard_update_model1/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000213, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1mruns/detect/storyboard_update_model1\u001b[0m\n","Starting training for 10 epochs...\n","Closing dataloader mosaic\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       1/10      2.37G      0.414      1.659     0.8305         10        640: 100% 369/369 [00:37<00:00,  9.86it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 62/62 [00:09<00:00,  6.27it/s]\n","                   all       1967       8234      0.727      0.709      0.776       0.71\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       2/10       2.4G     0.4152      1.538     0.8298         10        640: 100% 369/369 [00:33<00:00, 11.10it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 62/62 [00:09<00:00,  6.30it/s]\n","                   all       1967       8234      0.775      0.732      0.809      0.752\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       3/10      2.39G     0.4035      1.395      0.825          9        640: 100% 369/369 [00:32<00:00, 11.20it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 62/62 [00:09<00:00,  6.28it/s]\n","                   all       1967       8234        0.8       0.76      0.828      0.775\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       4/10       2.4G     0.3876      1.274     0.8234         10        640: 100% 369/369 [00:32<00:00, 11.50it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 62/62 [00:09<00:00,  6.30it/s]\n","                   all       1967       8234      0.821      0.782       0.85      0.799\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       5/10       2.4G     0.3756      1.174     0.8175          9        640: 100% 369/369 [00:32<00:00, 11.36it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 62/62 [00:09<00:00,  6.40it/s]\n","                   all       1967       8234      0.832      0.799      0.869      0.824\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       6/10       2.4G     0.3625      1.083     0.8156          9        640: 100% 369/369 [00:32<00:00, 11.47it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 62/62 [00:09<00:00,  6.28it/s]\n","                   all       1967       8234      0.833      0.819      0.877      0.833\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       7/10      2.38G     0.3496      1.015     0.8114          9        640: 100% 369/369 [00:32<00:00, 11.32it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 62/62 [00:09<00:00,  6.34it/s]\n","                   all       1967       8234      0.859      0.821      0.889      0.848\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       8/10      2.39G     0.3363     0.9479     0.8067          9        640: 100% 369/369 [00:32<00:00, 11.43it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 62/62 [00:09<00:00,  6.40it/s]\n","                   all       1967       8234      0.869      0.831      0.897      0.853\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       9/10      2.39G     0.3284     0.9106     0.8086         11        640: 100% 369/369 [00:32<00:00, 11.30it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 62/62 [00:09<00:00,  6.35it/s]\n","                   all       1967       8234      0.871      0.829      0.899       0.86\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      10/10      2.39G     0.3203     0.8643     0.8071         11        640: 100% 369/369 [00:32<00:00, 11.38it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 62/62 [00:09<00:00,  6.38it/s]\n","                   all       1967       8234      0.883      0.835      0.906      0.871\n","\n","10 epochs completed in 0.122 hours.\n","Optimizer stripped from runs/detect/storyboard_update_model1/weights/last.pt, 6.3MB\n","Optimizer stripped from runs/detect/storyboard_update_model1/weights/best.pt, 6.3MB\n","\n","Validating runs/detect/storyboard_update_model1/weights/best.pt...\n","Ultralytics YOLOv8.0.202 🚀 Python-3.10.12 torch-2.1.0+cu118 CUDA:0 (NVIDIA A100-SXM4-40GB, 40514MiB)\n","Model summary (fused): 168 layers, 3014033 parameters, 0 gradients, 8.1 GFLOPs\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   3% 2/62 [00:00<00:14,  4.28it/s]WARNING ⚠️ NMS time limit 2.100s exceeded\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 62/62 [00:14<00:00,  4.14it/s]\n","                   all       1967       8234      0.883      0.832      0.902      0.867\n","                 apple       1967        196      0.954       0.95      0.964      0.944\n","              backpack       1967        190      0.919      0.842      0.915      0.907\n","                banana       1967        199      0.904       0.93      0.945      0.931\n","            basketball       1967        182      0.788      0.777      0.866      0.845\n","                   bed       1967        167      0.789      0.626      0.772      0.743\n","               bicycle       1967        199      0.953      0.945      0.988      0.956\n","                  book       1967        175      0.855      0.914      0.943      0.908\n","                bucket       1967        200      0.939      0.917       0.95      0.923\n","                  cake       1967        179       0.93      0.838      0.903      0.871\n","              calendar       1967        191      0.818      0.707      0.819      0.798\n","                 chair       1967        211      0.903      0.929      0.956      0.914\n","                 clock       1967        199      0.981      0.915      0.968      0.954\n","                 couch       1967        185      0.912      0.805      0.924      0.896\n","                   dog       1967        171      0.745      0.752      0.816      0.786\n","              dumbbell       1967        196      0.879      0.781      0.858      0.807\n","            eyeglasses       1967        204      0.912      0.843      0.916      0.852\n","                   fan       1967        203      0.924      0.744      0.891      0.864\n","                guitar       1967        180      0.677      0.672      0.715      0.675\n","                   hat       1967        174      0.944      0.871      0.921      0.897\n","                jacket       1967        187      0.925      0.941      0.963      0.921\n","                   key       1967        196      0.777      0.832      0.865      0.827\n","                laptop       1967        179      0.837      0.905      0.948      0.926\n","                 pants       1967        181      0.993      0.838      0.966       0.94\n","                pencil       1967        198      0.906      0.823      0.912      0.843\n","                 piano       1967        195      0.726      0.749      0.811      0.756\n","                pillow       1967        211      0.899      0.768       0.86      0.805\n","                rabbit       1967        171      0.912       0.86       0.91      0.891\n","                 radio       1967        210      0.891      0.848      0.934      0.889\n","             saxophone       1967        204      0.926      0.887      0.938      0.904\n","                  shoe       1967        180      0.879      0.739      0.874      0.831\n","            skateboard       1967        210      0.947      0.881      0.953      0.898\n","                  sock       1967        207       0.88       0.86      0.912      0.896\n","                 spoon       1967        190      0.944      0.884      0.948      0.888\n","                 stove       1967        197       0.86      0.756      0.862      0.846\n","            strawberry       1967        186      0.954      0.902      0.974      0.929\n","                 table       1967        190      0.928      0.837      0.922      0.888\n","             telephone       1967        182      0.777      0.766      0.838      0.812\n","            television       1967        184       0.93      0.941      0.974      0.949\n","            toothbrush       1967        206      0.861      0.898      0.936       0.85\n","              umbrella       1967        204      0.975      0.961      0.979      0.962\n","                  vase       1967        195      0.969      0.801      0.928       0.88\n","                violin       1967        186       0.72      0.575        0.7      0.675\n","            watermelon       1967        184      0.817      0.755      0.848      0.819\n","Speed: 0.1ms preprocess, 0.5ms inference, 0.0ms loss, 2.5ms postprocess per image\n","Results saved to \u001b[1mruns/detect/storyboard_update_model1\u001b[0m\n","💡 Learn more at https://docs.ultralytics.com/modes/train\n"]}]},{"cell_type":"markdown","source":["## model training (storyboard with rotation)"],"metadata":{"id":"Y4ZI8DjStIZI"}},{"cell_type":"code","source":["# Use storyboard_update_model1 ->epochs = 3\n","%cd /content/drive/MyDrive/capstone/colab\n","!yolo train \\\n","  model= runs/detect/storyboard_update_model1/weights/best.pt \\\n","  data=storyboards/v2/storyboard.yml \\\n","  epochs=3 \\\n","  imgsz=640 \\\n","  name=\"storyboard_rotate_model\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kcePqv2ttOGK","executionInfo":{"status":"ok","timestamp":1700250005966,"user_tz":480,"elapsed":1037557,"user":{"displayName":"Cynthia Cheng","userId":"11720369831058397288"}},"outputId":"61a44568-df59-4711-b2e4-3eaab820c8a5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/.shortcut-targets-by-id/1xXZ2ldeRl7gFnlMnyoptyZpnfIdhf68X/capstone/colab\n","Ultralytics YOLOv8.0.211 🚀 Python-3.10.12 torch-2.1.0+cu118 CUDA:0 (Tesla V100-SXM2-16GB, 16151MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=runs/detect/storyboard_update_model1/weights/best.pt, data=storyboards/v2/storyboard.yml, epochs=3, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=storyboard_rotate_model, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/storyboard_rotate_model\n","Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n","100% 755k/755k [00:00<00:00, 46.6MB/s]\n","2023-11-17 19:22:55.634537: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2023-11-17 19:22:55.634591: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2023-11-17 19:22:55.634637: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n","  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n","  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n","  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n"," 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n"," 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 22        [15, 18, 21]  1    759697  ultralytics.nn.modules.head.Detect           [43, [64, 128, 256]]          \n","Model summary: 225 layers, 3019233 parameters, 3019217 gradients, 8.2 GFLOPs\n","\n","Transferred 355/355 items from pretrained weights\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/storyboard_rotate_model', view at http://localhost:6006/\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/.shortcut-targets-by-id/1xXZ2ldeRl7gFnlMnyoptyZpnfIdhf68X/capstone/colab/storyboards/v2/train/labels... 7985 images, 0 backgrounds, 0 corrupt: 100% 7985/7985 [10:29<00:00, 12.68it/s]\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/drive/.shortcut-targets-by-id/1xXZ2ldeRl7gFnlMnyoptyZpnfIdhf68X/capstone/colab/storyboards/v2/train/labels.cache\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/.shortcut-targets-by-id/1xXZ2ldeRl7gFnlMnyoptyZpnfIdhf68X/capstone/colab/storyboards/v2/valid/labels... 1889 images, 0 backgrounds, 0 corrupt: 100% 1889/1889 [02:20<00:00, 13.45it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/drive/.shortcut-targets-by-id/1xXZ2ldeRl7gFnlMnyoptyZpnfIdhf68X/capstone/colab/storyboards/v2/valid/labels.cache\n","Plotting labels to runs/detect/storyboard_rotate_model/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000213, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1mruns/detect/storyboard_rotate_model\u001b[0m\n","Starting training for 3 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","        1/3      2.46G     0.7511      1.813     0.8358          9        640: 100% 500/500 [01:00<00:00,  8.30it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 60/60 [00:11<00:00,  5.00it/s]\n","                   all       1889       5667        0.7      0.685      0.744      0.624\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","        2/3      2.45G     0.7127      1.549     0.8299          9        640: 100% 500/500 [00:55<00:00,  8.95it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 60/60 [00:10<00:00,  5.58it/s]\n","                   all       1889       5667      0.723      0.716      0.777      0.667\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","        3/3      2.46G     0.6931       1.43      0.829          6        640: 100% 500/500 [00:53<00:00,  9.39it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 60/60 [00:10<00:00,  5.76it/s]\n","                   all       1889       5667      0.752      0.741      0.803      0.682\n","\n","3 epochs completed in 0.057 hours.\n","Optimizer stripped from runs/detect/storyboard_rotate_model/weights/last.pt, 6.3MB\n","Optimizer stripped from runs/detect/storyboard_rotate_model/weights/best.pt, 6.3MB\n","\n","Validating runs/detect/storyboard_rotate_model/weights/best.pt...\n","Ultralytics YOLOv8.0.211 🚀 Python-3.10.12 torch-2.1.0+cu118 CUDA:0 (Tesla V100-SXM2-16GB, 16151MiB)\n","Model summary (fused): 168 layers, 3014033 parameters, 0 gradients, 8.1 GFLOPs\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 60/60 [00:14<00:00,  4.12it/s]\n","                   all       1889       5667      0.752      0.742      0.802      0.682\n","                 apple       1889        137      0.919      0.829      0.918      0.794\n","              backpack       1889        139      0.836       0.64      0.782      0.683\n","                banana       1889        117      0.883       0.84      0.918      0.771\n","            basketball       1889        114      0.723      0.711      0.807       0.71\n","                   bed       1889        131      0.654      0.496      0.638      0.549\n","               bicycle       1889        127      0.866      0.913      0.945      0.799\n","                  book       1889        132      0.672      0.864      0.845      0.723\n","                bucket       1889        135      0.939      0.906      0.941      0.797\n","                  cake       1889        135       0.85      0.815      0.879       0.75\n","              calendar       1889        144       0.71      0.628      0.735      0.639\n","                 chair       1889        152      0.923      0.794      0.879      0.735\n","                 clock       1889        158       0.86      0.962      0.973       0.87\n","                 couch       1889        133      0.663      0.789      0.838      0.718\n","                   dog       1889        135       0.54      0.644      0.677      0.568\n","              dumbbell       1889        133      0.706      0.624      0.673      0.565\n","            eyeglasses       1889        117      0.758      0.698      0.785      0.651\n","                   fan       1889        141      0.756       0.66       0.78      0.673\n","                guitar       1889        136      0.507      0.787      0.594      0.494\n","                   hat       1889        145      0.872      0.702      0.819      0.692\n","                jacket       1889        131      0.787      0.905       0.93      0.797\n","                   key       1889        119      0.563      0.529      0.559      0.463\n","                laptop       1889        119      0.736      0.832      0.857      0.745\n","                 pants       1889        136      0.877      0.887       0.93      0.808\n","                pencil       1889        121      0.766      0.893      0.914      0.737\n","                 piano       1889        105      0.618      0.447      0.535      0.456\n","                pillow       1889        144      0.897      0.701      0.833      0.714\n","                rabbit       1889        127      0.662      0.819       0.82      0.686\n","                 radio       1889        130      0.705      0.731      0.793       0.67\n","             saxophone       1889        115      0.603      0.878      0.854      0.721\n","                  shoe       1889        117      0.615      0.744      0.714      0.612\n","            skateboard       1889        145      0.834      0.814      0.885      0.702\n","                  sock       1889        140      0.805      0.677      0.797      0.684\n","                 spoon       1889        153      0.749       0.83      0.862      0.712\n","                 stove       1889        149      0.635      0.688      0.722      0.636\n","            strawberry       1889        130      0.859      0.841      0.908      0.774\n","                 table       1889        126      0.797       0.81      0.854      0.736\n","             telephone       1889        141      0.636      0.484      0.614      0.523\n","            television       1889        121      0.672      0.848      0.879      0.759\n","            toothbrush       1889        134      0.851      0.642      0.847      0.677\n","              umbrella       1889        114      0.942      0.807      0.912      0.784\n","                  vase       1889        133      0.906      0.699       0.85      0.714\n","                violin       1889        140      0.474      0.429      0.467      0.396\n","            watermelon       1889        116      0.723      0.651      0.743      0.636\n","Speed: 0.1ms preprocess, 0.7ms inference, 0.0ms loss, 1.8ms postprocess per image\n","Results saved to \u001b[1mruns/detect/storyboard_rotate_model\u001b[0m\n","💡 Learn more at https://docs.ultralytics.com/modes/train\n"]}]},{"cell_type":"code","source":["# Use storyboard_rotate_model ->epochs = 10\n","%cd /content/drive/MyDrive/capstone/colab\n","!yolo train \\\n","  model= runs/detect/storyboard_rotate_model/weights/last.pt \\\n","  data=storyboards/v2/storyboard.yml \\\n","  epochs=10 \\\n","  imgsz=640 \\\n","  name=\"storyboard_rotate_model1\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Tel4mc6ky-b8","executionInfo":{"status":"ok","timestamp":1700250711206,"user_tz":480,"elapsed":678590,"user":{"displayName":"Cynthia Cheng","userId":"11720369831058397288"}},"outputId":"9f9a9556-c244-44a9-9935-66ce239d989d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/.shortcut-targets-by-id/1xXZ2ldeRl7gFnlMnyoptyZpnfIdhf68X/capstone/colab\n","Ultralytics YOLOv8.0.211 🚀 Python-3.10.12 torch-2.1.0+cu118 CUDA:0 (Tesla V100-SXM2-16GB, 16151MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=runs/detect/storyboard_rotate_model/weights/last.pt, data=storyboards/v2/storyboard.yml, epochs=10, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=storyboard_rotate_model1, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/storyboard_rotate_model1\n","2023-11-17 19:40:37.283240: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2023-11-17 19:40:37.283292: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2023-11-17 19:40:37.283321: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n","  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n","  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n","  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n"," 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n"," 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 22        [15, 18, 21]  1    759697  ultralytics.nn.modules.head.Detect           [43, [64, 128, 256]]          \n","Model summary: 225 layers, 3019233 parameters, 3019217 gradients, 8.2 GFLOPs\n","\n","Transferred 355/355 items from pretrained weights\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/storyboard_rotate_model1', view at http://localhost:6006/\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/.shortcut-targets-by-id/1xXZ2ldeRl7gFnlMnyoptyZpnfIdhf68X/capstone/colab/storyboards/v2/train/labels.cache... 7985 images, 0 backgrounds, 0 corrupt: 100% 7985/7985 [00:00<?, ?it/s]\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/.shortcut-targets-by-id/1xXZ2ldeRl7gFnlMnyoptyZpnfIdhf68X/capstone/colab/storyboards/v2/valid/labels.cache... 1889 images, 0 backgrounds, 0 corrupt: 100% 1889/1889 [00:00<?, ?it/s]\n","Plotting labels to runs/detect/storyboard_rotate_model1/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000213, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1mruns/detect/storyboard_rotate_model1\u001b[0m\n","Starting training for 10 epochs...\n","Closing dataloader mosaic\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       1/10      2.43G     0.6569      1.277     0.8274          4        640: 100% 500/500 [00:57<00:00,  8.73it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 60/60 [00:10<00:00,  5.46it/s]\n","                   all       1889       5667      0.774      0.743      0.812      0.688\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       2/10      2.43G     0.6595      1.268     0.8257          4        640: 100% 500/500 [00:51<00:00,  9.66it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 60/60 [00:10<00:00,  5.79it/s]\n","                   all       1889       5667      0.765      0.749       0.81      0.682\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       3/10      2.44G     0.6604      1.231     0.8284          3        640: 100% 500/500 [00:50<00:00,  9.86it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 60/60 [00:10<00:00,  5.67it/s]\n","                   all       1889       5667      0.766      0.757      0.818      0.695\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       4/10      2.44G     0.6583      1.163     0.8286          4        640: 100% 500/500 [00:49<00:00, 10.07it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 60/60 [00:10<00:00,  5.75it/s]\n","                   all       1889       5667      0.772      0.774      0.831      0.705\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       5/10      2.44G      0.655      1.127     0.8285          3        640: 100% 500/500 [00:50<00:00,  9.91it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 60/60 [00:10<00:00,  5.67it/s]\n","                   all       1889       5667      0.784      0.773      0.839      0.715\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       6/10      2.44G     0.6461      1.071     0.8279          3        640: 100% 500/500 [00:49<00:00, 10.06it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 60/60 [00:10<00:00,  5.83it/s]\n","                   all       1889       5667      0.809      0.769      0.845      0.717\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       7/10      2.44G     0.6397      1.019      0.825          1        640: 100% 500/500 [00:50<00:00,  9.94it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 60/60 [00:10<00:00,  5.63it/s]\n","                   all       1889       5667      0.809      0.784      0.852      0.731\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       8/10      2.44G     0.6352     0.9798     0.8246          3        640: 100% 500/500 [00:49<00:00, 10.01it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 60/60 [00:10<00:00,  5.88it/s]\n","                   all       1889       5667      0.813        0.8       0.86      0.738\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       9/10      2.44G     0.6275     0.9348     0.8226          3        640: 100% 500/500 [00:50<00:00,  9.91it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 60/60 [00:10<00:00,  5.66it/s]\n","                   all       1889       5667      0.824      0.809      0.867      0.743\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      10/10      2.44G     0.6242     0.9086      0.823          4        640: 100% 500/500 [00:50<00:00,  9.85it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 60/60 [00:10<00:00,  5.73it/s]\n","                   all       1889       5667       0.83      0.811      0.874      0.755\n","\n","10 epochs completed in 0.174 hours.\n","Optimizer stripped from runs/detect/storyboard_rotate_model1/weights/last.pt, 6.3MB\n","Optimizer stripped from runs/detect/storyboard_rotate_model1/weights/best.pt, 6.3MB\n","\n","Validating runs/detect/storyboard_rotate_model1/weights/best.pt...\n","Ultralytics YOLOv8.0.211 🚀 Python-3.10.12 torch-2.1.0+cu118 CUDA:0 (Tesla V100-SXM2-16GB, 16151MiB)\n","Model summary (fused): 168 layers, 3014033 parameters, 0 gradients, 8.1 GFLOPs\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 60/60 [00:14<00:00,  4.02it/s]\n","                   all       1889       5667      0.833      0.808      0.874      0.754\n","                 apple       1889        137      0.908      0.862      0.943      0.818\n","              backpack       1889        139      0.819      0.791      0.865      0.767\n","                banana       1889        117      0.884      0.923      0.943      0.808\n","            basketball       1889        114      0.871      0.771      0.895      0.798\n","                   bed       1889        131      0.712      0.725      0.797      0.704\n","               bicycle       1889        127      0.863      0.929      0.964      0.834\n","                  book       1889        132      0.846      0.886      0.918      0.801\n","                bucket       1889        135       0.95      0.926      0.974      0.846\n","                  cake       1889        135      0.913       0.86      0.934       0.82\n","              calendar       1889        144      0.768      0.764      0.832      0.731\n","                 chair       1889        152      0.917      0.862      0.921      0.782\n","                 clock       1889        158      0.993      0.923      0.982      0.882\n","                 couch       1889        133      0.777      0.857      0.912       0.79\n","                   dog       1889        135      0.777      0.647      0.792      0.684\n","              dumbbell       1889        133      0.762      0.722      0.735      0.632\n","            eyeglasses       1889        117      0.869      0.737      0.883      0.739\n","                   fan       1889        141      0.765      0.766      0.816      0.713\n","                guitar       1889        136      0.575      0.815      0.635      0.537\n","                   hat       1889        145      0.847      0.821      0.891      0.758\n","                jacket       1889        131      0.915      0.931      0.969       0.84\n","                   key       1889        119      0.793      0.613      0.773      0.654\n","                laptop       1889        119       0.81      0.874      0.913      0.807\n","                 pants       1889        136      0.931      0.893      0.955      0.849\n","                pencil       1889        121      0.851      0.909      0.956      0.791\n","                 piano       1889        105      0.749      0.571      0.719      0.598\n","                pillow       1889        144      0.896      0.819       0.88      0.773\n","                rabbit       1889        127      0.735       0.85      0.852       0.73\n","                 radio       1889        130      0.818      0.795      0.876      0.753\n","             saxophone       1889        115      0.878      0.835      0.904      0.788\n","                  shoe       1889        117      0.758      0.644      0.793      0.677\n","            skateboard       1889        145      0.913      0.862      0.944      0.766\n","                  sock       1889        140      0.808      0.811      0.867      0.751\n","                 spoon       1889        153      0.907      0.804      0.927      0.783\n","                 stove       1889        149      0.786      0.705      0.808      0.715\n","            strawberry       1889        130      0.934      0.877      0.955      0.818\n","                 table       1889        126      0.785      0.868      0.889      0.787\n","             telephone       1889        141      0.844      0.616      0.782      0.673\n","            television       1889        121      0.809      0.912      0.936      0.823\n","            toothbrush       1889        134      0.891      0.851      0.923      0.746\n","              umbrella       1889        114      0.942      0.939      0.975       0.85\n","                  vase       1889        133        0.9      0.797      0.907      0.775\n","                violin       1889        140      0.542      0.626      0.589      0.508\n","            watermelon       1889        116      0.785      0.741       0.86      0.745\n","Speed: 0.2ms preprocess, 0.7ms inference, 0.0ms loss, 1.9ms postprocess per image\n","Results saved to \u001b[1mruns/detect/storyboard_rotate_model1\u001b[0m\n","💡 Learn more at https://docs.ultralytics.com/modes/train\n"]}]},{"cell_type":"code","source":["# Use storyboard_rotate_model1 ->epochs = 10\n","%cd /content/drive/MyDrive/capstone/colab\n","!yolo train \\\n","  model= runs/detect/storyboard_rotate_model1/weights/last.pt \\\n","  data=storyboards/v2/storyboard.yml \\\n","  epochs=10 \\\n","  imgsz=640 \\\n","  name=\"storyboard_rotate_model2\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5wQotrwV1q8C","executionInfo":{"status":"ok","timestamp":1700251398606,"user_tz":480,"elapsed":673670,"user":{"displayName":"Cynthia Cheng","userId":"11720369831058397288"}},"outputId":"90409056-75b2-4bc0-a26c-07bc648f9c7d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/.shortcut-targets-by-id/1xXZ2ldeRl7gFnlMnyoptyZpnfIdhf68X/capstone/colab\n","Ultralytics YOLOv8.0.211 🚀 Python-3.10.12 torch-2.1.0+cu118 CUDA:0 (Tesla V100-SXM2-16GB, 16151MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=runs/detect/storyboard_rotate_model1/weights/last.pt, data=storyboards/v2/storyboard.yml, epochs=10, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=storyboard_rotate_model2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, vid_stride=1, stream_buffer=False, line_width=None, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/storyboard_rotate_model2\n","2023-11-17 19:52:09.736382: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2023-11-17 19:52:09.736436: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2023-11-17 19:52:09.736466: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n","  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n","  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n","  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n"," 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n"," 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 22        [15, 18, 21]  1    759697  ultralytics.nn.modules.head.Detect           [43, [64, 128, 256]]          \n","Model summary: 225 layers, 3019233 parameters, 3019217 gradients, 8.2 GFLOPs\n","\n","Transferred 355/355 items from pretrained weights\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/storyboard_rotate_model2', view at http://localhost:6006/\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/.shortcut-targets-by-id/1xXZ2ldeRl7gFnlMnyoptyZpnfIdhf68X/capstone/colab/storyboards/v2/train/labels.cache... 7985 images, 0 backgrounds, 0 corrupt: 100% 7985/7985 [00:00<?, ?it/s]\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/.shortcut-targets-by-id/1xXZ2ldeRl7gFnlMnyoptyZpnfIdhf68X/capstone/colab/storyboards/v2/valid/labels.cache... 1889 images, 0 backgrounds, 0 corrupt: 100% 1889/1889 [00:00<?, ?it/s]\n","Plotting labels to runs/detect/storyboard_rotate_model2/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000213, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1mruns/detect/storyboard_rotate_model2\u001b[0m\n","Starting training for 10 epochs...\n","Closing dataloader mosaic\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       1/10      2.43G      0.623     0.8807     0.8243          4        640: 100% 500/500 [00:56<00:00,  8.82it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 60/60 [00:10<00:00,  5.57it/s]\n","                   all       1889       5667      0.841      0.797      0.869      0.743\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       2/10      2.43G     0.6288     0.9083     0.8235          4        640: 100% 500/500 [00:51<00:00,  9.74it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 60/60 [00:10<00:00,  5.66it/s]\n","                   all       1889       5667      0.819      0.801      0.861      0.739\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       3/10      2.44G     0.6334     0.9117     0.8268          3        640: 100% 500/500 [00:50<00:00,  9.84it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 60/60 [00:10<00:00,  5.49it/s]\n","                   all       1889       5667      0.805      0.805      0.857       0.73\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       4/10      2.44G     0.6323     0.8905     0.8268          4        640: 100% 500/500 [00:50<00:00,  9.88it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 60/60 [00:10<00:00,  5.61it/s]\n","                   all       1889       5667      0.828       0.79      0.865      0.739\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       5/10      2.44G      0.631      0.884     0.8268          3        640: 100% 500/500 [00:50<00:00,  9.97it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 60/60 [00:10<00:00,  5.64it/s]\n","                   all       1889       5667       0.82      0.792       0.86      0.745\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       6/10      2.44G     0.6245     0.8526     0.8268          3        640: 100% 500/500 [00:50<00:00,  9.96it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 60/60 [00:10<00:00,  5.67it/s]\n","                   all       1889       5667       0.83      0.801      0.866      0.737\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       7/10      2.44G     0.6201     0.8212     0.8247          1        640: 100% 500/500 [00:49<00:00, 10.02it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 60/60 [00:10<00:00,  5.70it/s]\n","                   all       1889       5667      0.838      0.797      0.868      0.749\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       8/10      2.44G     0.6175      0.797     0.8245          3        640: 100% 500/500 [00:50<00:00,  9.96it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 60/60 [00:10<00:00,  5.78it/s]\n","                   all       1889       5667      0.839      0.806      0.872      0.747\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       9/10      2.44G     0.6132     0.7697     0.8229          3        640: 100% 500/500 [00:48<00:00, 10.21it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 60/60 [00:10<00:00,  5.93it/s]\n","                   all       1889       5667      0.854      0.806      0.879      0.756\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      10/10      2.44G     0.6109     0.7593     0.8236          4        640: 100% 500/500 [00:48<00:00, 10.21it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 60/60 [00:10<00:00,  5.73it/s]\n","                   all       1889       5667      0.852       0.82      0.884      0.765\n","\n","10 epochs completed in 0.173 hours.\n","Optimizer stripped from runs/detect/storyboard_rotate_model2/weights/last.pt, 6.3MB\n","Optimizer stripped from runs/detect/storyboard_rotate_model2/weights/best.pt, 6.3MB\n","\n","Validating runs/detect/storyboard_rotate_model2/weights/best.pt...\n","Ultralytics YOLOv8.0.211 🚀 Python-3.10.12 torch-2.1.0+cu118 CUDA:0 (Tesla V100-SXM2-16GB, 16151MiB)\n","Model summary (fused): 168 layers, 3014033 parameters, 0 gradients, 8.1 GFLOPs\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 60/60 [00:14<00:00,  4.27it/s]\n","                   all       1889       5667      0.851      0.821      0.884      0.765\n","                 apple       1889        137      0.937      0.869      0.942      0.821\n","              backpack       1889        139      0.888      0.777      0.856      0.757\n","                banana       1889        117      0.893      0.931      0.943      0.808\n","            basketball       1889        114       0.83      0.816      0.889      0.791\n","                   bed       1889        131      0.724      0.733      0.805      0.712\n","               bicycle       1889        127      0.886      0.945      0.966      0.846\n","                  book       1889        132      0.897      0.864      0.929      0.813\n","                bucket       1889        135      0.961      0.904      0.971      0.845\n","                  cake       1889        135      0.918      0.896      0.937      0.825\n","              calendar       1889        144      0.777       0.75      0.848      0.745\n","                 chair       1889        152      0.936      0.882      0.927      0.796\n","                 clock       1889        158      0.986      0.968      0.985      0.883\n","                 couch       1889        133       0.82      0.887      0.907      0.784\n","                   dog       1889        135      0.801      0.741      0.832      0.724\n","              dumbbell       1889        133       0.81      0.722      0.767      0.657\n","            eyeglasses       1889        117        0.9      0.773      0.894      0.747\n","                   fan       1889        141      0.779      0.787      0.829      0.725\n","                guitar       1889        136      0.597      0.816      0.668      0.561\n","                   hat       1889        145      0.885      0.828      0.902      0.776\n","                jacket       1889        131      0.926      0.947      0.969      0.841\n","                   key       1889        119      0.832      0.709      0.839       0.71\n","                laptop       1889        119      0.863      0.874       0.92      0.815\n","                 pants       1889        136      0.945      0.897      0.965      0.855\n","                pencil       1889        121      0.854      0.901      0.952      0.791\n","                 piano       1889        105      0.738      0.638      0.754      0.643\n","                pillow       1889        144      0.886      0.758      0.876      0.769\n","                rabbit       1889        127       0.78      0.843      0.882      0.761\n","                 radio       1889        130       0.88      0.793      0.893      0.773\n","             saxophone       1889        115      0.876      0.858      0.896      0.789\n","                  shoe       1889        117      0.769      0.675      0.809      0.692\n","            skateboard       1889        145      0.911      0.849      0.942      0.768\n","                  sock       1889        140      0.827       0.82      0.876      0.766\n","                 spoon       1889        153      0.933      0.797      0.937      0.785\n","                 stove       1889        149      0.769      0.715      0.817       0.73\n","            strawberry       1889        130      0.928      0.893       0.95      0.813\n","                 table       1889        126      0.792      0.875      0.884       0.78\n","             telephone       1889        141      0.836      0.674      0.817        0.7\n","            television       1889        121      0.811      0.959      0.937      0.827\n","            toothbrush       1889        134      0.919      0.852      0.937      0.766\n","              umbrella       1889        114      0.932      0.958      0.984      0.858\n","                  vase       1889        133      0.908      0.805      0.909      0.773\n","                violin       1889        140      0.617      0.579      0.621      0.536\n","            watermelon       1889        116      0.822       0.75      0.864      0.754\n","Speed: 0.1ms preprocess, 0.7ms inference, 0.0ms loss, 1.7ms postprocess per image\n","Results saved to \u001b[1mruns/detect/storyboard_rotate_model2\u001b[0m\n","💡 Learn more at https://docs.ultralytics.com/modes/train\n"]}]},{"cell_type":"markdown","source":["## model training (storyborad with scaling)"],"metadata":{"id":"zedLJpLvpLT5"}},{"cell_type":"code","source":["# Use storyboard_update_model1 ->epochs = 3\n","%cd /content/drive/MyDrive/capstone/colab\n","!yolo train \\\n","  model= runs/detect/storyboard_rotate_model2/weights/best.pt \\\n","  data=storyboards/v3/storyboard.yml \\\n","  epochs=3 \\\n","  imgsz=640 \\\n","  name=\"storyboard_scale_model\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SavBSfMzpKs4","executionInfo":{"status":"ok","timestamp":1700953077125,"user_tz":480,"elapsed":732582,"user":{"displayName":"Cynthia Cheng","userId":"11720369831058397288"}},"outputId":"75d4040d-b54c-40b1-ee0f-0bc1cec51a97"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/.shortcut-targets-by-id/1xXZ2ldeRl7gFnlMnyoptyZpnfIdhf68X/capstone/colab\n","Ultralytics YOLOv8.0.218 🚀 Python-3.10.12 torch-2.1.0+cu118 CUDA:0 (Tesla V100-SXM2-16GB, 16151MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=runs/detect/storyboard_rotate_model2/weights/best.pt, data=storyboards/v3/storyboard.yml, epochs=3, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=storyboard_scale_model, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/storyboard_scale_model\n","Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n","100% 755k/755k [00:00<00:00, 22.6MB/s]\n","2023-11-25 22:45:51.332674: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2023-11-25 22:45:51.332733: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2023-11-25 22:45:51.332792: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n","  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n","  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n","  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n"," 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n"," 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 22        [15, 18, 21]  1    759697  ultralytics.nn.modules.head.Detect           [43, [64, 128, 256]]          \n","Model summary: 225 layers, 3019233 parameters, 3019217 gradients, 8.2 GFLOPs\n","\n","Transferred 355/355 items from pretrained weights\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/storyboard_scale_model', view at http://localhost:6006/\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/.shortcut-targets-by-id/1xXZ2ldeRl7gFnlMnyoptyZpnfIdhf68X/capstone/colab/storyboards/v3/train/labels... 7311 images, 0 backgrounds, 0 corrupt: 100% 7311/7311 [06:48<00:00, 17.88it/s]\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/drive/.shortcut-targets-by-id/1xXZ2ldeRl7gFnlMnyoptyZpnfIdhf68X/capstone/colab/storyboards/v3/train/labels.cache\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/.shortcut-targets-by-id/1xXZ2ldeRl7gFnlMnyoptyZpnfIdhf68X/capstone/colab/storyboards/v3/valid/labels... 1798 images, 0 backgrounds, 0 corrupt: 100% 1798/1798 [01:26<00:00, 20.84it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/drive/.shortcut-targets-by-id/1xXZ2ldeRl7gFnlMnyoptyZpnfIdhf68X/capstone/colab/storyboards/v3/valid/labels.cache\n","Plotting labels to runs/detect/storyboard_scale_model/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000213, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1mruns/detect/storyboard_scale_model\u001b[0m\n","Starting training for 3 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","        1/3      2.41G     0.7524      1.168     0.9316         46        640: 100% 457/457 [00:52<00:00,  8.75it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 57/57 [00:11<00:00,  5.13it/s]\n","                   all       1798       6490      0.741      0.633      0.722      0.575\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","        2/3      2.41G     0.6821      1.073     0.8986         52        640: 100% 457/457 [00:47<00:00,  9.65it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 57/57 [00:10<00:00,  5.42it/s]\n","                   all       1798       6490      0.776      0.651       0.75      0.613\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","        3/3      2.41G     0.6603      1.023     0.8885         61        640: 100% 457/457 [00:47<00:00,  9.72it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 57/57 [00:10<00:00,  5.67it/s]\n","                   all       1798       6490       0.78      0.671      0.767      0.607\n","\n","3 epochs completed in 0.051 hours.\n","Optimizer stripped from runs/detect/storyboard_scale_model/weights/last.pt, 6.3MB\n","Optimizer stripped from runs/detect/storyboard_scale_model/weights/best.pt, 6.3MB\n","\n","Validating runs/detect/storyboard_scale_model/weights/best.pt...\n","Ultralytics YOLOv8.0.218 🚀 Python-3.10.12 torch-2.1.0+cu118 CUDA:0 (Tesla V100-SXM2-16GB, 16151MiB)\n","Model summary (fused): 168 layers, 3014033 parameters, 0 gradients, 8.1 GFLOPs\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 57/57 [00:14<00:00,  4.07it/s]\n","                   all       1798       6490      0.778      0.649       0.75      0.613\n","                 apple       1798        160      0.836      0.799      0.875      0.728\n","              backpack       1798        148      0.887      0.507      0.718      0.604\n","                banana       1798        158      0.775      0.787      0.835      0.691\n","            basketball       1798        142      0.757      0.599      0.753      0.622\n","                   bed       1798        150      0.631       0.62      0.651      0.528\n","               bicycle       1798        146      0.831      0.781      0.872      0.721\n","                  book       1798        156      0.674      0.718      0.763      0.651\n","                bucket       1798        131      0.947       0.71      0.851      0.721\n","                  cake       1798        167      0.701      0.778      0.816      0.694\n","              calendar       1798        133       0.57      0.618      0.627      0.526\n","                 chair       1798        156      0.801      0.802       0.87      0.717\n","                 clock       1798        144      0.881      0.764      0.897      0.762\n","                 couch       1798        141      0.973      0.504      0.789      0.671\n","                   dog       1798        136      0.605      0.559      0.605      0.488\n","              dumbbell       1798        131      0.748      0.634      0.703       0.59\n","            eyeglasses       1798        157      0.772      0.624      0.747      0.608\n","                   fan       1798        162      0.744      0.673      0.739      0.641\n","                guitar       1798        161      0.556       0.59      0.559      0.454\n","                   hat       1798        142      0.921      0.574      0.679      0.535\n","                jacket       1798        162      0.827      0.648      0.795      0.652\n","                   key       1798        163      0.782      0.393      0.564      0.437\n","                laptop       1798        154      0.867      0.669      0.824      0.696\n","                 pants       1798        168      0.959      0.701       0.91      0.726\n","                pencil       1798        152      0.714      0.757      0.782      0.566\n","                 piano       1798        170      0.576      0.614      0.632       0.52\n","                pillow       1798        164      0.909      0.555      0.702      0.558\n","                rabbit       1798        160      0.674      0.738      0.761      0.605\n","                 radio       1798        159      0.906      0.548      0.779      0.636\n","             saxophone       1798        142      0.596      0.718      0.754      0.625\n","                  shoe       1798        167      0.844      0.479      0.647      0.506\n","            skateboard       1798        151      0.855      0.755      0.862      0.686\n","                  sock       1798        136      0.738      0.662      0.753      0.617\n","                 spoon       1798        132       0.82      0.619       0.73      0.569\n","                 stove       1798        140      0.869      0.421      0.642      0.533\n","            strawberry       1798        142      0.746      0.732      0.813      0.651\n","                 table       1798        132      0.784      0.758      0.809      0.662\n","             telephone       1798        154      0.804      0.506      0.621      0.499\n","            television       1798        157      0.873      0.669      0.817      0.686\n","            toothbrush       1798        140      0.807      0.777      0.842      0.641\n","              umbrella       1798        150      0.927      0.833      0.919      0.767\n","                  vase       1798        172      0.893      0.605      0.754        0.6\n","                violin       1798        151      0.529      0.365       0.46      0.365\n","            watermelon       1798        151      0.538      0.728      0.712      0.598\n","Speed: 0.1ms preprocess, 0.7ms inference, 0.0ms loss, 0.9ms postprocess per image\n","Results saved to \u001b[1mruns/detect/storyboard_scale_model\u001b[0m\n","💡 Learn more at https://docs.ultralytics.com/modes/train\n"]}]},{"cell_type":"code","source":["# Use storyboard_scale_model ->epochs = 10\n","%cd /content/drive/MyDrive/capstone/colab\n","!yolo train \\\n","  model= runs/detect/storyboard_scale_model/weights/best.pt \\\n","  data=storyboards/v3/storyboard.yml \\\n","  epochs=10 \\\n","  imgsz=640 \\\n","  name=\"storyboard_scale_model1\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HIofdFVetzC5","executionInfo":{"status":"ok","timestamp":1700953924805,"user_tz":480,"elapsed":637581,"user":{"displayName":"Cynthia Cheng","userId":"11720369831058397288"}},"outputId":"023dbd95-de17-445c-9420-6f1bd424c0dd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/.shortcut-targets-by-id/1xXZ2ldeRl7gFnlMnyoptyZpnfIdhf68X/capstone/colab\n","Ultralytics YOLOv8.0.218 🚀 Python-3.10.12 torch-2.1.0+cu118 CUDA:0 (Tesla V100-SXM2-16GB, 16151MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=runs/detect/storyboard_scale_model/weights/best.pt, data=storyboards/v3/storyboard.yml, epochs=10, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=storyboard_scale_model1, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/storyboard_scale_model1\n","2023-11-25 23:01:30.707938: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2023-11-25 23:01:30.707993: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2023-11-25 23:01:30.708032: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n","  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n","  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n","  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n"," 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n"," 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 22        [15, 18, 21]  1    759697  ultralytics.nn.modules.head.Detect           [43, [64, 128, 256]]          \n","Model summary: 225 layers, 3019233 parameters, 3019217 gradients, 8.2 GFLOPs\n","\n","Transferred 355/355 items from pretrained weights\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/storyboard_scale_model1', view at http://localhost:6006/\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/.shortcut-targets-by-id/1xXZ2ldeRl7gFnlMnyoptyZpnfIdhf68X/capstone/colab/storyboards/v3/train/labels.cache... 7311 images, 0 backgrounds, 0 corrupt: 100% 7311/7311 [00:00<?, ?it/s]\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/.shortcut-targets-by-id/1xXZ2ldeRl7gFnlMnyoptyZpnfIdhf68X/capstone/colab/storyboards/v3/valid/labels.cache... 1798 images, 0 backgrounds, 0 corrupt: 100% 1798/1798 [00:00<?, ?it/s]\n","Plotting labels to runs/detect/storyboard_scale_model1/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000213, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1mruns/detect/storyboard_scale_model1\u001b[0m\n","Starting training for 10 epochs...\n","Closing dataloader mosaic\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       1/10      2.39G     0.6287     0.9476     0.8768         40        640: 100% 457/457 [00:51<00:00,  8.86it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 57/57 [00:09<00:00,  5.72it/s]\n","                   all       1798       6490      0.782      0.673       0.77      0.623\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       2/10      2.39G     0.6266     0.9677     0.8729         43        640: 100% 457/457 [00:49<00:00,  9.25it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 57/57 [00:09<00:00,  5.91it/s]\n","                   all       1798       6490      0.769      0.678      0.769      0.622\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       3/10       2.4G     0.6237     0.9635     0.8713         42        640: 100% 457/457 [00:50<00:00,  9.11it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 57/57 [00:10<00:00,  5.42it/s]\n","                   all       1798       6490       0.76      0.685      0.771       0.64\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       4/10       2.4G     0.6208     0.9279     0.8708         44        640: 100% 457/457 [00:49<00:00,  9.18it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 57/57 [00:10<00:00,  5.65it/s]\n","                   all       1798       6490      0.786      0.675      0.783       0.64\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       5/10       2.4G     0.6169     0.9154     0.8666         44        640: 100% 457/457 [00:50<00:00,  9.08it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 57/57 [00:10<00:00,  5.64it/s]\n","                   all       1798       6490      0.774       0.71      0.793       0.66\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       6/10      2.39G     0.6081     0.8708     0.8672         40        640: 100% 457/457 [00:45<00:00, 10.05it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 57/57 [00:09<00:00,  5.83it/s]\n","                   all       1798       6490       0.78      0.702       0.79       0.65\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       7/10       2.4G     0.5998     0.8427     0.8617         42        640: 100% 457/457 [00:45<00:00,  9.97it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 57/57 [00:09<00:00,  5.87it/s]\n","                   all       1798       6490        0.8      0.712      0.804      0.672\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       8/10      2.39G     0.5914     0.7932     0.8585         42        640: 100% 457/457 [00:45<00:00,  9.96it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 57/57 [00:09<00:00,  5.72it/s]\n","                   all       1798       6490      0.791      0.714      0.802      0.668\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       9/10      2.39G     0.5882     0.7729     0.8586         43        640: 100% 457/457 [00:45<00:00,  9.98it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 57/57 [00:10<00:00,  5.60it/s]\n","                   all       1798       6490      0.811      0.723      0.815      0.683\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      10/10      2.39G     0.5762     0.7382     0.8549         43        640: 100% 457/457 [00:45<00:00, 10.14it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 57/57 [00:10<00:00,  5.58it/s]\n","                   all       1798       6490      0.824      0.725      0.822      0.684\n","\n","10 epochs completed in 0.164 hours.\n","Optimizer stripped from runs/detect/storyboard_scale_model1/weights/last.pt, 6.3MB\n","Optimizer stripped from runs/detect/storyboard_scale_model1/weights/best.pt, 6.3MB\n","\n","Validating runs/detect/storyboard_scale_model1/weights/best.pt...\n","Ultralytics YOLOv8.0.218 🚀 Python-3.10.12 torch-2.1.0+cu118 CUDA:0 (Tesla V100-SXM2-16GB, 16151MiB)\n","Model summary (fused): 168 layers, 3014033 parameters, 0 gradients, 8.1 GFLOPs\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   4% 2/57 [00:00<00:13,  4.06it/s]WARNING ⚠️ NMS time limit 2.100s exceeded\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 57/57 [00:14<00:00,  3.98it/s]\n","                   all       1798       6490      0.825      0.717      0.815      0.678\n","                 apple       1798        160      0.929      0.831      0.926      0.782\n","              backpack       1798        148       0.77      0.723      0.811        0.7\n","                banana       1798        158      0.926      0.787      0.913      0.766\n","            basketball       1798        142      0.736       0.69      0.785      0.668\n","                   bed       1798        150      0.739      0.624      0.725      0.592\n","               bicycle       1798        146      0.884      0.877      0.933      0.787\n","                  book       1798        156      0.856      0.737      0.854      0.729\n","                bucket       1798        131      0.912      0.779      0.858      0.723\n","                  cake       1798        167      0.818      0.826      0.887      0.751\n","              calendar       1798        133      0.594      0.677      0.658      0.569\n","                 chair       1798        156      0.916      0.834      0.925      0.758\n","                 clock       1798        144      0.848      0.854      0.909      0.783\n","                 couch       1798        141      0.867      0.709      0.849      0.733\n","                   dog       1798        136      0.625      0.699      0.706      0.584\n","              dumbbell       1798        131      0.918      0.599      0.767      0.644\n","            eyeglasses       1798        157       0.79      0.764       0.82      0.666\n","                   fan       1798        162      0.788      0.691      0.791      0.683\n","                guitar       1798        161      0.729      0.627      0.706      0.582\n","                   hat       1798        142      0.841      0.662      0.731      0.591\n","                jacket       1798        162      0.835      0.751      0.861      0.722\n","                   key       1798        163      0.676      0.663      0.762      0.608\n","                laptop       1798        154      0.828      0.805       0.87      0.746\n","                 pants       1798        168      0.923      0.845      0.953      0.791\n","                pencil       1798        152      0.817      0.705      0.821       0.62\n","                 piano       1798        170      0.638      0.671      0.707      0.581\n","                pillow       1798        164      0.833      0.677      0.772      0.631\n","                rabbit       1798        160      0.872      0.688      0.838      0.675\n","                 radio       1798        159      0.914      0.648      0.834      0.703\n","             saxophone       1798        142      0.896      0.746      0.847      0.709\n","                  shoe       1798        167      0.823      0.585      0.756      0.619\n","            skateboard       1798        151      0.935      0.758      0.871      0.712\n","                  sock       1798        136      0.741      0.779      0.814      0.693\n","                 spoon       1798        132      0.854      0.622      0.758      0.613\n","                 stove       1798        140      0.788      0.536      0.671      0.573\n","            strawberry       1798        142      0.877      0.806      0.902      0.754\n","                 table       1798        132      0.813      0.765      0.838      0.696\n","             telephone       1798        154      0.787      0.647      0.739      0.612\n","            television       1798        157      0.896      0.766      0.881      0.749\n","            toothbrush       1798        140      0.909      0.743      0.879      0.669\n","              umbrella       1798        150      0.936      0.867      0.942      0.795\n","                  vase       1798        172      0.919      0.729      0.862      0.702\n","                violin       1798        151      0.636      0.483      0.553      0.444\n","            watermelon       1798        151      0.832      0.556      0.746      0.637\n","Speed: 0.1ms preprocess, 0.7ms inference, 0.0ms loss, 2.6ms postprocess per image\n","Results saved to \u001b[1mruns/detect/storyboard_scale_model1\u001b[0m\n","💡 Learn more at https://docs.ultralytics.com/modes/train\n"]}]},{"cell_type":"code","source":["# Use storyboard_scale_model1 ->epochs = 10\n","%cd /content/drive/MyDrive/capstone/colab\n","!yolo train \\\n","  model= runs/detect/storyboard_scale_model1/weights/best.pt \\\n","  data=storyboards/v3/storyboard.yml \\\n","  epochs=10 \\\n","  imgsz=640 \\\n","  name=\"storyboard_scale_model2\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MPQBxJbCwV63","executionInfo":{"status":"ok","timestamp":1700954551431,"user_tz":480,"elapsed":597205,"user":{"displayName":"Cynthia Cheng","userId":"11720369831058397288"}},"outputId":"593396ab-795e-4c47-d630-ded1ad6d67c3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/.shortcut-targets-by-id/1xXZ2ldeRl7gFnlMnyoptyZpnfIdhf68X/capstone/colab\n","Ultralytics YOLOv8.0.218 🚀 Python-3.10.12 torch-2.1.0+cu118 CUDA:0 (Tesla V100-SXM2-16GB, 16151MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=runs/detect/storyboard_scale_model1/weights/best.pt, data=storyboards/v3/storyboard.yml, epochs=10, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=storyboard_scale_model2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/storyboard_scale_model2\n","2023-11-25 23:12:37.636302: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2023-11-25 23:12:37.636353: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2023-11-25 23:12:37.636380: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n","  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n","  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n","  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n"," 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n"," 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 22        [15, 18, 21]  1    759697  ultralytics.nn.modules.head.Detect           [43, [64, 128, 256]]          \n","Model summary: 225 layers, 3019233 parameters, 3019217 gradients, 8.2 GFLOPs\n","\n","Transferred 355/355 items from pretrained weights\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/storyboard_scale_model2', view at http://localhost:6006/\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/.shortcut-targets-by-id/1xXZ2ldeRl7gFnlMnyoptyZpnfIdhf68X/capstone/colab/storyboards/v3/train/labels.cache... 7311 images, 0 backgrounds, 0 corrupt: 100% 7311/7311 [00:00<?, ?it/s]\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/.shortcut-targets-by-id/1xXZ2ldeRl7gFnlMnyoptyZpnfIdhf68X/capstone/colab/storyboards/v3/valid/labels.cache... 1798 images, 0 backgrounds, 0 corrupt: 100% 1798/1798 [00:00<?, ?it/s]\n","Plotting labels to runs/detect/storyboard_scale_model2/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000213, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1mruns/detect/storyboard_scale_model2\u001b[0m\n","Starting training for 10 epochs...\n","Closing dataloader mosaic\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       1/10      2.39G     0.5794     0.7169     0.8564         40        640: 100% 457/457 [00:50<00:00,  9.05it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 57/57 [00:09<00:00,  5.85it/s]\n","                   all       1798       6490      0.815      0.715       0.81      0.668\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       2/10      2.39G     0.5841     0.7372     0.8547         43        640: 100% 457/457 [00:45<00:00, 10.09it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 57/57 [00:09<00:00,  5.95it/s]\n","                   all       1798       6490      0.782       0.72      0.797      0.656\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       3/10      2.39G     0.5846     0.7498     0.8563         42        640: 100% 457/457 [00:44<00:00, 10.37it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 57/57 [00:10<00:00,  5.66it/s]\n","                   all       1798       6490      0.792      0.694      0.787      0.656\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       4/10      2.39G     0.5866      0.742     0.8564         44        640: 100% 457/457 [00:43<00:00, 10.48it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 57/57 [00:09<00:00,  5.94it/s]\n","                   all       1798       6490      0.798        0.7      0.796      0.656\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       5/10      2.39G     0.5856     0.7396      0.855         44        640: 100% 457/457 [00:43<00:00, 10.48it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 57/57 [00:09<00:00,  6.04it/s]\n","                   all       1798       6490        0.8      0.703      0.796      0.668\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       6/10      2.39G     0.5782     0.7198     0.8556         40        640: 100% 457/457 [00:43<00:00, 10.45it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 57/57 [00:09<00:00,  6.22it/s]\n","                   all       1798       6490       0.79      0.705      0.791       0.66\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       7/10      2.39G     0.5745     0.6979     0.8521         42        640: 100% 457/457 [00:43<00:00, 10.47it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 57/57 [00:09<00:00,  6.11it/s]\n","                   all       1798       6490      0.803      0.707      0.803      0.676\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       8/10      2.39G     0.5695     0.6663     0.8507         42        640: 100% 457/457 [00:43<00:00, 10.42it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 57/57 [00:09<00:00,  5.97it/s]\n","                   all       1798       6490      0.814      0.719      0.811      0.681\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       9/10      2.39G     0.5672       0.66     0.8504         43        640: 100% 457/457 [00:43<00:00, 10.51it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 57/57 [00:09<00:00,  5.98it/s]\n","                   all       1798       6490      0.833      0.705      0.814      0.684\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      10/10      2.39G     0.5582     0.6379     0.8482         43        640: 100% 457/457 [00:43<00:00, 10.52it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 57/57 [00:09<00:00,  5.86it/s]\n","                   all       1798       6490      0.826      0.726      0.822      0.692\n","\n","10 epochs completed in 0.153 hours.\n","Optimizer stripped from runs/detect/storyboard_scale_model2/weights/last.pt, 6.3MB\n","Optimizer stripped from runs/detect/storyboard_scale_model2/weights/best.pt, 6.3MB\n","\n","Validating runs/detect/storyboard_scale_model2/weights/best.pt...\n","Ultralytics YOLOv8.0.218 🚀 Python-3.10.12 torch-2.1.0+cu118 CUDA:0 (Tesla V100-SXM2-16GB, 16151MiB)\n","Model summary (fused): 168 layers, 3014033 parameters, 0 gradients, 8.1 GFLOPs\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   4% 2/57 [00:00<00:12,  4.38it/s]WARNING ⚠️ NMS time limit 2.100s exceeded\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 57/57 [00:13<00:00,  4.09it/s]\n","                   all       1798       6490      0.826      0.724       0.82       0.69\n","                 apple       1798        160       0.93      0.825      0.907      0.767\n","              backpack       1798        148      0.801      0.709      0.805      0.696\n","                banana       1798        158      0.918      0.781      0.905      0.761\n","            basketball       1798        142      0.728      0.736      0.796       0.68\n","                   bed       1798        150      0.725       0.66      0.739      0.618\n","               bicycle       1798        146      0.876       0.89      0.939      0.797\n","                  book       1798        156      0.883      0.756      0.865      0.747\n","                bucket       1798        131      0.917      0.756      0.887      0.756\n","                  cake       1798        167      0.872      0.808      0.887      0.761\n","              calendar       1798        133      0.556      0.699       0.66      0.577\n","                 chair       1798        156      0.936      0.808      0.926      0.774\n","                 clock       1798        144      0.877      0.861      0.927      0.801\n","                 couch       1798        141      0.868      0.723      0.844      0.732\n","                   dog       1798        136      0.648       0.69      0.691      0.583\n","              dumbbell       1798        131      0.938       0.58      0.779      0.659\n","            eyeglasses       1798        157      0.787      0.753       0.82      0.683\n","                   fan       1798        162      0.806      0.693      0.789      0.682\n","                guitar       1798        161      0.768      0.584      0.734      0.618\n","                   hat       1798        142       0.84      0.669      0.751      0.615\n","                jacket       1798        162      0.882      0.772      0.861       0.73\n","                   key       1798        163      0.715      0.677      0.769      0.623\n","                laptop       1798        154      0.924      0.786      0.887      0.771\n","                 pants       1798        168      0.898       0.89      0.956      0.805\n","                pencil       1798        152        0.8      0.738       0.84      0.648\n","                 piano       1798        170      0.652      0.671      0.718      0.599\n","                pillow       1798        164      0.673      0.762       0.74       0.63\n","                rabbit       1798        160      0.876       0.65      0.818      0.663\n","                 radio       1798        159      0.892      0.676      0.856       0.73\n","             saxophone       1798        142      0.901      0.718      0.842      0.712\n","                  shoe       1798        167      0.838      0.588      0.761      0.628\n","            skateboard       1798        151      0.898      0.775      0.873      0.717\n","                  sock       1798        136      0.733      0.794      0.836      0.714\n","                 spoon       1798        132       0.83      0.606      0.773      0.625\n","                 stove       1798        140      0.784      0.529      0.673       0.58\n","            strawberry       1798        142       0.87       0.81      0.908      0.766\n","                 table       1798        132      0.794      0.758      0.841      0.701\n","             telephone       1798        154      0.771      0.669      0.753      0.626\n","            television       1798        157      0.887      0.797      0.902      0.772\n","            toothbrush       1798        140       0.89      0.753      0.867      0.676\n","              umbrella       1798        150      0.923      0.882      0.946      0.807\n","                  vase       1798        172      0.925      0.767      0.864      0.715\n","                violin       1798        151      0.706      0.477      0.572      0.464\n","            watermelon       1798        151      0.786      0.603      0.749      0.644\n","Speed: 0.2ms preprocess, 0.7ms inference, 0.0ms loss, 2.0ms postprocess per image\n","Results saved to \u001b[1mruns/detect/storyboard_scale_model2\u001b[0m\n","💡 Learn more at https://docs.ultralytics.com/modes/train\n"]}]},{"cell_type":"markdown","source":["## Detection"],"metadata":{"id":"FuJIAFKk2OJC"}},{"cell_type":"code","source":["# Run inference on an image with YOLOv8n\n","%cd /content/drive/MyDrive/capstone/colab\n","!yolo predict model=runs/detect/storyboard_scale_model2/weights/best.pt \\\n","  source='reference/storyboards/storyboard_008.png'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SyMAu5602RoD","executionInfo":{"status":"ok","timestamp":1701661761901,"user_tz":480,"elapsed":5228,"user":{"displayName":"Cynthia Cheng","userId":"11720369831058397288"}},"outputId":"d7499234-8aeb-4f1d-d28e-8351e2945b76"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/.shortcut-targets-by-id/1xXZ2ldeRl7gFnlMnyoptyZpnfIdhf68X/capstone/colab\n","Ultralytics YOLOv8.0.222 🚀 Python-3.10.12 torch-2.1.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n","Model summary (fused): 168 layers, 3014033 parameters, 0 gradients, 8.1 GFLOPs\n","\n","image 1/1 /content/drive/.shortcut-targets-by-id/1xXZ2ldeRl7gFnlMnyoptyZpnfIdhf68X/capstone/colab/reference/storyboards/storyboard_008.png: 640x640 1 calendar, 1 clock, 2 dumbbells, 1 sock, 1 table, 7.5ms\n","Speed: 3.2ms preprocess, 7.5ms inference, 78.2ms postprocess per image at shape (1, 3, 640, 640)\n","Results saved to \u001b[1mruns/detect/predict31\u001b[0m\n","💡 Learn more at https://docs.ultralytics.com/modes/predict\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[],"gpuType":"T4","toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}